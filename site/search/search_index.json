{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"Introduction/","text":"Introduction to QueryStorm About these docs Welcome to the QueryStorm documentation. You can read these pages from beginning to end, or pick and choose topics that interest you. SQL users, for example, can freely skip sections that cover .NET related topics. Each section of the documentation starts with an overview page explaining the core concepts covered in the section. What is QueryStorm QueryStorm is an Excel add-in that brings first class support for modern programming languages (namely SQL, C# and VB.NET) into Excel. It is intended to enhance Excel's native functionality with a strong set of technical capabilities. It has three main areas of application: Querying and migrating data Automating workbooks Developing and sharing custom Excel functions Who it's for The main audiences for QueryStorm can be split into three distinct groups: Data specialists such as database professionals, data scientists and data analysts use it to facilitate processing of data in Excel, as well as moving data between Excel and databases. Developers use if for building workbook-applications with rich behavior as well as custom functions for their users and clients. Business users use it to make use of the custom functions and workbook applications that developers and data specialists build for them. IDE and Runtime QueryStorm consists of two parts: the IDE and the Runtime . These are two separate add-ins that function independently. The main QueryStorm installer installs both parts, but the runtime can also be installed separately via its own (smaller) installer. The IDE is used by data professionals and developers for data processing and for creating custom functions and workbook applications. The Runtime is used by business users for installing and using those custom solutions.","title":"Introduction"},{"location":"Introduction/#introduction-to-querystorm","text":"","title":"Introduction to QueryStorm"},{"location":"Introduction/#about-these-docs","text":"Welcome to the QueryStorm documentation. You can read these pages from beginning to end, or pick and choose topics that interest you. SQL users, for example, can freely skip sections that cover .NET related topics. Each section of the documentation starts with an overview page explaining the core concepts covered in the section.","title":"About these docs"},{"location":"Introduction/#what-is-querystorm","text":"QueryStorm is an Excel add-in that brings first class support for modern programming languages (namely SQL, C# and VB.NET) into Excel. It is intended to enhance Excel's native functionality with a strong set of technical capabilities. It has three main areas of application: Querying and migrating data Automating workbooks Developing and sharing custom Excel functions","title":"What is QueryStorm"},{"location":"Introduction/#who-its-for","text":"The main audiences for QueryStorm can be split into three distinct groups: Data specialists such as database professionals, data scientists and data analysts use it to facilitate processing of data in Excel, as well as moving data between Excel and databases. Developers use if for building workbook-applications with rich behavior as well as custom functions for their users and clients. Business users use it to make use of the custom functions and workbook applications that developers and data specialists build for them.","title":"Who it's for"},{"location":"Introduction/#ide-and-runtime","text":"QueryStorm consists of two parts: the IDE and the Runtime . These are two separate add-ins that function independently. The main QueryStorm installer installs both parts, but the runtime can also be installed separately via its own (smaller) installer. The IDE is used by data professionals and developers for data processing and for creating custom functions and workbook applications. The Runtime is used by business users for installing and using those custom solutions.","title":"IDE and Runtime"},{"location":"Automation/Automation_with_SQL/","text":"SQL commands Automation in QueryStorm is usually implemented by writing C# or VB.NET code inside component classes, as described in the previous chapter . However, this code does not necessarily need to be written by hand. SQL scripts can generate the component code automatically, which is especially useful for SQL users who are not familiar with C# and VB.NET. These scripts are called SQL commands . For this reason (among others) QueryStorm introduces a preprocessor syntax for SQL. With SQL commands, SQL code is used to fetch/update data while preprocessor code is used to specify when the script should be executed, and where the results should be written to (e.g. an Excel table). Example Let's suppose we want to populate an Excel table with sales orders for a given date. When the value of the cell that contains the date changes, we want the script to execute again and to output the new results into the table. Here's how we might do that: 1 2 3 4 5 6 7 8 9 10 11 -- specify the triggers that call the command { handles orderDate } -- output results into the 'orders' table { @ orders } select * from Sales . SalesOrderHeader soh where OrderDate = @ orderDate -- read the orderDate cell's value Starting the application In order to start the application, the script needs to be saved ( Ctrl + S ), and the project built ( Ctrl + Shift + B ). The component code is generated when the script is saved. After the build completes, the runtime loads and activates the workbook application. Accessing workbook tables and variables All cells with assigned names are visible inside scripts as parameters. The code in the previous example uses a cell called orderDate as a parameter. To allow the script to access Excel tables as well, the tables must be included when configuring the script via the \"Connect\" dialog. Outputting query results The preprocessor allows sending query results into Excel (via the data context). In the example above, the {@orders} output directive is used to send the results of the select query into an Excel table called orders . The syntax of the output directive is very simple: {@ table_name } The output directive should be placed above the select query whose results it should output. If there are multiple select queries in the script, each of them can have its own output directive, so multiple tables can be updated from the same script. Specifying triggers The preprocessor syntax for declaring an automation command is: { handles eventsList }. The event list is a comma separated list of events that should trigger execution of the command. Range change events For each named cell, an event with the same name is defined, and is fired each time the cell value changes. In the above example, the orderDate event is specified as the only trigger, meaning that the command will execute every time the orderDate cell's value changes. ActiveX button click events To handle the click of an ActiveX button, we should use the following syntax: { handles sheetName ! buttonName }, for example {handles Sheet!CommandButton1} . VBA events Arbitrarily named events can also be sent from VBA and used to trigger execution of commands. To send an event from VBA, use the QueryStorm.Runtime.API class: 1 CreateObject(\"QueryStorm.Runtime.API\").SendEvent(\"myEvent\") The event can be handled using the preprocessor like so: {handles myEvent} Scripts can handle multiple events. Event names should be separated by a comma: 1 2 3 4 5 { handles myEvent , orderDate , Sheet1 ! CommandButton1 } { @ orders } select ... Commands vs Functions The preprocessor supports defining commands as well as functions . The command and function declarations are mutually exclusive. A script can either declare a command or a function, but not both. Example function declaration: 1 2 { function myFunc ( int param1 = 1 , string param2 = \"abc\" ) } // ... sql code Example command declaration: 1 2 { handles myNamedCell , Sheet1 ! MyButton } // ... sql code In general, functions fetch or calculate values while commands change things (e.g. save data to a database, write data into Excel tables). In the example at the beginning of this page, we were fetching data based on some parameter. Conceptually, this looks more like it should be a function than a command. However, a function cannot return the body of a table, it can only return data to a cell or a range. If we want to write the resulting data to an Excel table, we need to use a command with an output directive (e.g. {@someTable} ). On the the other hand, if the script was updating database data rather than simply selecting data from it, a command would certainly be the appropriate choice. An important distinction between commands and functions is that commands reset Excel's Undo/Redo stack when they modify data in the workbook, while functions do not. This is a technical limitation in Excel.","title":"Automation with SQL Commands"},{"location":"Automation/Automation_with_SQL/#sql-commands","text":"Automation in QueryStorm is usually implemented by writing C# or VB.NET code inside component classes, as described in the previous chapter . However, this code does not necessarily need to be written by hand. SQL scripts can generate the component code automatically, which is especially useful for SQL users who are not familiar with C# and VB.NET. These scripts are called SQL commands . For this reason (among others) QueryStorm introduces a preprocessor syntax for SQL. With SQL commands, SQL code is used to fetch/update data while preprocessor code is used to specify when the script should be executed, and where the results should be written to (e.g. an Excel table).","title":"SQL commands"},{"location":"Automation/Automation_with_SQL/#example","text":"Let's suppose we want to populate an Excel table with sales orders for a given date. When the value of the cell that contains the date changes, we want the script to execute again and to output the new results into the table. Here's how we might do that: 1 2 3 4 5 6 7 8 9 10 11 -- specify the triggers that call the command { handles orderDate } -- output results into the 'orders' table { @ orders } select * from Sales . SalesOrderHeader soh where OrderDate = @ orderDate -- read the orderDate cell's value","title":"Example"},{"location":"Automation/Automation_with_SQL/#starting-the-application","text":"In order to start the application, the script needs to be saved ( Ctrl + S ), and the project built ( Ctrl + Shift + B ). The component code is generated when the script is saved. After the build completes, the runtime loads and activates the workbook application.","title":"Starting the application"},{"location":"Automation/Automation_with_SQL/#accessing-workbook-tables-and-variables","text":"All cells with assigned names are visible inside scripts as parameters. The code in the previous example uses a cell called orderDate as a parameter. To allow the script to access Excel tables as well, the tables must be included when configuring the script via the \"Connect\" dialog.","title":"Accessing workbook tables and variables"},{"location":"Automation/Automation_with_SQL/#outputting-query-results","text":"The preprocessor allows sending query results into Excel (via the data context). In the example above, the {@orders} output directive is used to send the results of the select query into an Excel table called orders . The syntax of the output directive is very simple: {@ table_name } The output directive should be placed above the select query whose results it should output. If there are multiple select queries in the script, each of them can have its own output directive, so multiple tables can be updated from the same script.","title":"Outputting query results"},{"location":"Automation/Automation_with_SQL/#specifying-triggers","text":"The preprocessor syntax for declaring an automation command is: { handles eventsList }. The event list is a comma separated list of events that should trigger execution of the command.","title":"Specifying triggers"},{"location":"Automation/Automation_with_SQL/#range-change-events","text":"For each named cell, an event with the same name is defined, and is fired each time the cell value changes. In the above example, the orderDate event is specified as the only trigger, meaning that the command will execute every time the orderDate cell's value changes.","title":"Range change events"},{"location":"Automation/Automation_with_SQL/#activex-button-click-events","text":"To handle the click of an ActiveX button, we should use the following syntax: { handles sheetName ! buttonName }, for example {handles Sheet!CommandButton1} .","title":"ActiveX button click events"},{"location":"Automation/Automation_with_SQL/#vba-events","text":"Arbitrarily named events can also be sent from VBA and used to trigger execution of commands. To send an event from VBA, use the QueryStorm.Runtime.API class: 1 CreateObject(\"QueryStorm.Runtime.API\").SendEvent(\"myEvent\") The event can be handled using the preprocessor like so: {handles myEvent} Scripts can handle multiple events. Event names should be separated by a comma: 1 2 3 4 5 { handles myEvent , orderDate , Sheet1 ! CommandButton1 } { @ orders } select ...","title":"VBA events"},{"location":"Automation/Automation_with_SQL/#commands-vs-functions","text":"The preprocessor supports defining commands as well as functions . The command and function declarations are mutually exclusive. A script can either declare a command or a function, but not both. Example function declaration: 1 2 { function myFunc ( int param1 = 1 , string param2 = \"abc\" ) } // ... sql code Example command declaration: 1 2 { handles myNamedCell , Sheet1 ! MyButton } // ... sql code In general, functions fetch or calculate values while commands change things (e.g. save data to a database, write data into Excel tables). In the example at the beginning of this page, we were fetching data based on some parameter. Conceptually, this looks more like it should be a function than a command. However, a function cannot return the body of a table, it can only return data to a cell or a range. If we want to write the resulting data to an Excel table, we need to use a command with an output directive (e.g. {@someTable} ). On the the other hand, if the script was updating database data rather than simply selecting data from it, a command would certainly be the appropriate choice. An important distinction between commands and functions is that commands reset Excel's Undo/Redo stack when they modify data in the workbook, while functions do not. This is a technical limitation in Excel.","title":"Commands vs Functions"},{"location":"Automation/Automation_with_dotnet/","text":"Workbook automation with .NET QueryStorm allows using C# and VB.NET to automate Excel workbooks. It offers a model binding approach that is designed to minimize the amount of code that's needed to interact with Excel (though you can freely interact with Excel via its COM API as well). Click below for a video example of the model-binding approach: Creating the project To automate the workbook, we must first add a project to it: This will create a project and prepare module.config and app.cs files that we can use as the starting point for out workbook application. When this project is built, the output files (.dll and .manifest) will be stored inside the workbook, and the runtime will automatically load the project. Each time an Excel workbook is opened, the QueryStorm runtime inspects it to see if there's a compiled workbook application inside it. If it finds one, it loads it along with the workbook. When the workbook is closed, the application is unloaded with it. The App class The workbook project has an App class that's defined in the App.cs (or App.vb ) file. This is the entry point of the application. In its constructor, we can request an IWorkbookAccessor instance which will give us access to the workbook that contains the application. We can use the workbook object to read and write cell values, subscribe to events, refresh graphs and pivot tables etc. For example, we can pop up a message box each time a cell is selected (though admittedly, this is not a very useful thing to do): 1 2 3 4 5 6 7 8 9 10 11 public App ( IUnityContainer container , IWorkbookAccessor workbookAccessor , IDialogService dialogService ) : base ( container ) { workbookAccessor . Workbook . SheetSelectionChange += ( sh , rng )=> { dialogService . ShowInfo ( $ \"Selected cell {rng.Address} with value '{rng.Value}'\" , \"Selected cell changed\" ); }; } In most cases, however, it's better to leave Excel interactions to QueryStorm's model binding infrastructure, and only use the COM API in special cases. Dependency injection The constructor of the App class in the example above, accepts several parameters which are provided by the QueryStorm runtime via dependency injection. The IWorkbookAccessor service is used to access the workbook, and the IDialogService is used to display a message to the user. Each workbook application is provided (by the QueryStorm runtime) its own IOC container, which comes pre-populated with some basic services. It is the responsibility of the App class to register any additional services that other parts of the application might need. For example: 1 2 3 4 5 6 public App ( IUnityContainer container ) : base ( container ) { // register a service (as a singleton) container . RegisterType < SomeService >( new ContainerControlledLifetimeManager ()); } The IOC container is used to create instances of other classes, such as the data context, components and function container classes, so all of those classes can accept dependencies via their constructors. For example, a component can access a service via constructor injection, like so: 1 2 3 4 5 6 7 public class Component1 { public Component1 ( SomeService someService ) { // ... } } QueryStorm uses the Unity container for dependency injection. Components A component class contains logic that controls a section of the workbook. You can have any number of components in a workbook, each controlling it's own (arbitrarily defined) part of the workbook. Components have the following characteristics: They can accept dependencies via constructor injection. Public properties of a component can be data-bound to cells in Excel via the [Bind] attribute and to tables via the [BindTable] attribute. The methods of the component can handle events coming from Excel (e.g. button click), which is specified using the [EventHandler] attribute. For example, the following component reads a searchText parameter from a cell in Excel. Each time that cell's value changes, the component updates a table called People (by putting a star next to each name that contains the searchText), and writes a message into a cell named messages : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 using System ; using System.Collections.Generic ; using System.Linq ; using System.Windows.Forms ; using QueryStorm.Core ; using static QueryStorm . Core . DebugHelpers ; namespace Project { public class Component1 : ComponentBase { [Bind(\"searchText\")] public string SearchText { get ; set ; } [BindTable] public PeopleTable People { get ; set ; } private string _Message ; [Bind(\"messages\")] public string Message { get => _Message ; set { _Message = value ; OnPropertyChanged ( nameof ( Message )); } } [EventHandler(\"searchText\")] public void Test () { Message = $ \"Searched for '{SearchText}' at {DateTime.Now.ToShortTimeString()}\" ; People . ForEach ( t => { string nameWithoutStar = t . FirstName . TrimEnd ( '*' ); if ( t . FirstName . IndexOf ( SearchText , StringComparison . OrdinalIgnoreCase ) >= 0 ) t . FirstName = nameWithoutStar + \"*\" ; else t . FirstName = nameWithoutStar ; }); People . SaveChanges (); } } } And here is the resulting behavior: The important thing to note is that no part of the code interacts with Excel directly. The component only accesses its own properties, and the binding infrastructure takes care of communicating with Excel. Bindings Bindings allow you to read and write values from Excel without having to access Excel objects directly or subscribe to their events to listen for changes. Bindings and the data context It's important to note that components aren't bound to Excel directly; they don't actually know anything about Excel. Instead, they are bound to a data context . For workbook applications, this data context happens to be a WorkbookDataContext instance that exposes data and events from the workbook. You can customize this data context, by adding a data context file from the project's context menu: The data context file allows you to: register additional tables override column types for workbook tables add relations between workbook tables For more information about the data context, click here . Binding to cells Component properties can be bound to cells in Excel. This is achieved by using the [Bind(nameOfCell)] attribute. By default, bindings are bi-directional. When the user changes the value of a cell, any property that's bound to the cell also gets updated to the new value. On the other hand, when a component changes the value of one of its properties, any cells that are bound to that property also get updated to the new value. For the binding infrastructure to detect the change, however, the component should raise a PropertyChanged event by calling e.g. OnPropertyChange(nameof(MyProperty123)) . This is typically done in the setter of the property. Binding to tables A component's property can also bind to an Excel table, which is done using the [BindTable(tableName)] attribute. This allows the component to read and update table data. In the previous example, we've used the following code to access the data in the People table: 1 2 [BindTable] public PeopleTable People { get ; set ; } You might be wondering where the PeopleTable class came from. The answer is: it was generated automatically. Each time you change any of the tables in your workbook, QueryStorm dynamically generates a dll with types that offer strongly typed access to the data they contain. This dll is then added to the lib folder of the project. The generated_types.dll file is also recreated after each successful build of the project, just in case you've customized the data context in the project. The generated classes inside this dll provide strongly typed read/write access to data inside tables. It's important to note that any changes you make to the data need to be explicitly saved by calling SaveChanges() on the table. In C# scripts, SaveChanges() is called automatically after each run, but in model-binding this call needs to be explicit. Events Components can handle events coming in from the workbook by defining public void methods marked with the EventHandler attribute. Multiple EventHandler attributes can be applied to a method in case the same method should handle multiple events. Currently, the following event sources are supported (by the WorkbookDataContext ): ActiveX button (Click) Range (value changed) VBA (sent via the QueryStorm Runtime API) The event name, which is the single argument to the EventHandler attribute, determines which event the method will handle. Handling button click events When a method needs to handle the click of an ActiveX button, the following syntax should be used for the event name: {sheetName}!{buttonName} . For example, to handle the click of an ActiveX button named MyButton located on a sheet named Sheet1 , the method should be decorated as follows: 1 2 3 4 5 [EventHandler(\"Sheet1!MyButton\")] public void MyEventHandlerMethod () { // ... } Handling range value changes When a method needs to be called every time a range changes, the name of the range should be used as the event name: 1 2 3 4 5 [EventHandler(\"nameOfTheCell\")] public void MyEventHandlerMethod () { // ... } Sending and handling events from VBA Events can be sent from VBA code to the workbook application. This offers full flexibility with regards to sending events. One particular reason this might be useful is that it allows using regular buttons to send events, instead of ActiveX buttons which have known issues when changing resolution (e.g. second screen, projector). To send an event from VBA, use the QueryStorm.Runtime.API class, like so: 1 CreateObject ( \"QueryStorm.Runtime.API\" ). SendEvent ( \"myEvent\" ) Instances of the QueryStorm.Runtime.API class are lightweight objects that forward messages to the QueryStorm Runtime. They carry no state and do not need to be cached. Handling the event is simple: 1 2 3 4 5 [EventHandler(\"myEvent\")] public void MyEventHandlerMethod () { // ... }","title":"Automation with .Net"},{"location":"Automation/Automation_with_dotnet/#workbook-automation-with-net","text":"QueryStorm allows using C# and VB.NET to automate Excel workbooks. It offers a model binding approach that is designed to minimize the amount of code that's needed to interact with Excel (though you can freely interact with Excel via its COM API as well). Click below for a video example of the model-binding approach:","title":"Workbook automation with .NET"},{"location":"Automation/Automation_with_dotnet/#creating-the-project","text":"To automate the workbook, we must first add a project to it: This will create a project and prepare module.config and app.cs files that we can use as the starting point for out workbook application. When this project is built, the output files (.dll and .manifest) will be stored inside the workbook, and the runtime will automatically load the project. Each time an Excel workbook is opened, the QueryStorm runtime inspects it to see if there's a compiled workbook application inside it. If it finds one, it loads it along with the workbook. When the workbook is closed, the application is unloaded with it.","title":"Creating the project"},{"location":"Automation/Automation_with_dotnet/#the-app-class","text":"The workbook project has an App class that's defined in the App.cs (or App.vb ) file. This is the entry point of the application. In its constructor, we can request an IWorkbookAccessor instance which will give us access to the workbook that contains the application. We can use the workbook object to read and write cell values, subscribe to events, refresh graphs and pivot tables etc. For example, we can pop up a message box each time a cell is selected (though admittedly, this is not a very useful thing to do): 1 2 3 4 5 6 7 8 9 10 11 public App ( IUnityContainer container , IWorkbookAccessor workbookAccessor , IDialogService dialogService ) : base ( container ) { workbookAccessor . Workbook . SheetSelectionChange += ( sh , rng )=> { dialogService . ShowInfo ( $ \"Selected cell {rng.Address} with value '{rng.Value}'\" , \"Selected cell changed\" ); }; } In most cases, however, it's better to leave Excel interactions to QueryStorm's model binding infrastructure, and only use the COM API in special cases.","title":"The App class"},{"location":"Automation/Automation_with_dotnet/#dependency-injection","text":"The constructor of the App class in the example above, accepts several parameters which are provided by the QueryStorm runtime via dependency injection. The IWorkbookAccessor service is used to access the workbook, and the IDialogService is used to display a message to the user. Each workbook application is provided (by the QueryStorm runtime) its own IOC container, which comes pre-populated with some basic services. It is the responsibility of the App class to register any additional services that other parts of the application might need. For example: 1 2 3 4 5 6 public App ( IUnityContainer container ) : base ( container ) { // register a service (as a singleton) container . RegisterType < SomeService >( new ContainerControlledLifetimeManager ()); } The IOC container is used to create instances of other classes, such as the data context, components and function container classes, so all of those classes can accept dependencies via their constructors. For example, a component can access a service via constructor injection, like so: 1 2 3 4 5 6 7 public class Component1 { public Component1 ( SomeService someService ) { // ... } } QueryStorm uses the Unity container for dependency injection.","title":"Dependency injection"},{"location":"Automation/Automation_with_dotnet/#components","text":"A component class contains logic that controls a section of the workbook. You can have any number of components in a workbook, each controlling it's own (arbitrarily defined) part of the workbook. Components have the following characteristics: They can accept dependencies via constructor injection. Public properties of a component can be data-bound to cells in Excel via the [Bind] attribute and to tables via the [BindTable] attribute. The methods of the component can handle events coming from Excel (e.g. button click), which is specified using the [EventHandler] attribute. For example, the following component reads a searchText parameter from a cell in Excel. Each time that cell's value changes, the component updates a table called People (by putting a star next to each name that contains the searchText), and writes a message into a cell named messages : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 using System ; using System.Collections.Generic ; using System.Linq ; using System.Windows.Forms ; using QueryStorm.Core ; using static QueryStorm . Core . DebugHelpers ; namespace Project { public class Component1 : ComponentBase { [Bind(\"searchText\")] public string SearchText { get ; set ; } [BindTable] public PeopleTable People { get ; set ; } private string _Message ; [Bind(\"messages\")] public string Message { get => _Message ; set { _Message = value ; OnPropertyChanged ( nameof ( Message )); } } [EventHandler(\"searchText\")] public void Test () { Message = $ \"Searched for '{SearchText}' at {DateTime.Now.ToShortTimeString()}\" ; People . ForEach ( t => { string nameWithoutStar = t . FirstName . TrimEnd ( '*' ); if ( t . FirstName . IndexOf ( SearchText , StringComparison . OrdinalIgnoreCase ) >= 0 ) t . FirstName = nameWithoutStar + \"*\" ; else t . FirstName = nameWithoutStar ; }); People . SaveChanges (); } } } And here is the resulting behavior: The important thing to note is that no part of the code interacts with Excel directly. The component only accesses its own properties, and the binding infrastructure takes care of communicating with Excel.","title":"Components"},{"location":"Automation/Automation_with_dotnet/#bindings","text":"Bindings allow you to read and write values from Excel without having to access Excel objects directly or subscribe to their events to listen for changes.","title":"Bindings"},{"location":"Automation/Automation_with_dotnet/#bindings-and-the-data-context","text":"It's important to note that components aren't bound to Excel directly; they don't actually know anything about Excel. Instead, they are bound to a data context . For workbook applications, this data context happens to be a WorkbookDataContext instance that exposes data and events from the workbook. You can customize this data context, by adding a data context file from the project's context menu: The data context file allows you to: register additional tables override column types for workbook tables add relations between workbook tables For more information about the data context, click here .","title":"Bindings and the data context"},{"location":"Automation/Automation_with_dotnet/#binding-to-cells","text":"Component properties can be bound to cells in Excel. This is achieved by using the [Bind(nameOfCell)] attribute. By default, bindings are bi-directional. When the user changes the value of a cell, any property that's bound to the cell also gets updated to the new value. On the other hand, when a component changes the value of one of its properties, any cells that are bound to that property also get updated to the new value. For the binding infrastructure to detect the change, however, the component should raise a PropertyChanged event by calling e.g. OnPropertyChange(nameof(MyProperty123)) . This is typically done in the setter of the property.","title":"Binding to cells"},{"location":"Automation/Automation_with_dotnet/#binding-to-tables","text":"A component's property can also bind to an Excel table, which is done using the [BindTable(tableName)] attribute. This allows the component to read and update table data. In the previous example, we've used the following code to access the data in the People table: 1 2 [BindTable] public PeopleTable People { get ; set ; } You might be wondering where the PeopleTable class came from. The answer is: it was generated automatically. Each time you change any of the tables in your workbook, QueryStorm dynamically generates a dll with types that offer strongly typed access to the data they contain. This dll is then added to the lib folder of the project. The generated_types.dll file is also recreated after each successful build of the project, just in case you've customized the data context in the project. The generated classes inside this dll provide strongly typed read/write access to data inside tables. It's important to note that any changes you make to the data need to be explicitly saved by calling SaveChanges() on the table. In C# scripts, SaveChanges() is called automatically after each run, but in model-binding this call needs to be explicit.","title":"Binding to tables"},{"location":"Automation/Automation_with_dotnet/#events","text":"Components can handle events coming in from the workbook by defining public void methods marked with the EventHandler attribute. Multiple EventHandler attributes can be applied to a method in case the same method should handle multiple events. Currently, the following event sources are supported (by the WorkbookDataContext ): ActiveX button (Click) Range (value changed) VBA (sent via the QueryStorm Runtime API) The event name, which is the single argument to the EventHandler attribute, determines which event the method will handle.","title":"Events"},{"location":"Automation/Automation_with_dotnet/#handling-button-click-events","text":"When a method needs to handle the click of an ActiveX button, the following syntax should be used for the event name: {sheetName}!{buttonName} . For example, to handle the click of an ActiveX button named MyButton located on a sheet named Sheet1 , the method should be decorated as follows: 1 2 3 4 5 [EventHandler(\"Sheet1!MyButton\")] public void MyEventHandlerMethod () { // ... }","title":"Handling button click events"},{"location":"Automation/Automation_with_dotnet/#handling-range-value-changes","text":"When a method needs to be called every time a range changes, the name of the range should be used as the event name: 1 2 3 4 5 [EventHandler(\"nameOfTheCell\")] public void MyEventHandlerMethod () { // ... }","title":"Handling range value changes"},{"location":"Automation/Automation_with_dotnet/#sending-and-handling-events-from-vba","text":"Events can be sent from VBA code to the workbook application. This offers full flexibility with regards to sending events. One particular reason this might be useful is that it allows using regular buttons to send events, instead of ActiveX buttons which have known issues when changing resolution (e.g. second screen, projector). To send an event from VBA, use the QueryStorm.Runtime.API class, like so: 1 CreateObject ( \"QueryStorm.Runtime.API\" ). SendEvent ( \"myEvent\" ) Instances of the QueryStorm.Runtime.API class are lightweight objects that forward messages to the QueryStorm Runtime. They carry no state and do not need to be cached. Handling the event is simple: 1 2 3 4 5 [EventHandler(\"myEvent\")] public void MyEventHandlerMethod () { // ... }","title":"Sending and handling events from VBA"},{"location":"Automation/Overview/","text":"Automating workbooks Excel files offer data storage capabilities and a flexible user interface for data entry and visualization. However, Excel files aren't just static documents containing data; they can also have behavior, in effect, making the workbook a hybrid between a document and an application. Out of the box, Microsoft Excel allows automating workbooks using VBA. However, VBA is quite old and hasn't kept up with the new programming paradigms and ecosystems. QueryStorm offers the ability to use modern programming languages as well as access to the .NET ecosystem when automating workbooks. Automation via .NET QueryStorm lets you automate Excel using C# and VB.NET. Your classes can interact with the Excel API directly, but they can also use QueryStorm's model-binding API, which minimizes the amount of Excel interaction code and lets you focus on the logic of your application. In addition, your code can reference NuGet packages and existing .NET dlls, making it easy to use proprietary and 3rd party libraries in your workbook applications. For more information about automation via .NET, click here . SQL-based automation QueryStorm also allows setting up automation from SQL scripts. These scripts typically contain SQL code extended with a simple preprocessor syntax. The job of the SQL code is to interact with the database, while the job of the preprocessor code is to interact with Excel, specifically, to send query results into the workbook and to specify which events will trigger the execution of the script. For more information about automation via SQL, click here .","title":"Overview"},{"location":"Automation/Overview/#automating-workbooks","text":"Excel files offer data storage capabilities and a flexible user interface for data entry and visualization. However, Excel files aren't just static documents containing data; they can also have behavior, in effect, making the workbook a hybrid between a document and an application. Out of the box, Microsoft Excel allows automating workbooks using VBA. However, VBA is quite old and hasn't kept up with the new programming paradigms and ecosystems. QueryStorm offers the ability to use modern programming languages as well as access to the .NET ecosystem when automating workbooks.","title":"Automating workbooks"},{"location":"Automation/Overview/#automation-via-net","text":"QueryStorm lets you automate Excel using C# and VB.NET. Your classes can interact with the Excel API directly, but they can also use QueryStorm's model-binding API, which minimizes the amount of Excel interaction code and lets you focus on the logic of your application. In addition, your code can reference NuGet packages and existing .NET dlls, making it easy to use proprietary and 3rd party libraries in your workbook applications. For more information about automation via .NET, click here .","title":"Automation via .NET"},{"location":"Automation/Overview/#sql-based-automation","text":"QueryStorm also allows setting up automation from SQL scripts. These scripts typically contain SQL code extended with a simple preprocessor syntax. The job of the SQL code is to interact with the database, while the job of the preprocessor code is to interact with Excel, specifically, to send query results into the workbook and to specify which events will trigger the execution of the script. For more information about automation via SQL, click here .","title":"SQL-based automation"},{"location":"Functions/Functions_via_DotNet/","text":"Defining functions with .NET The process of defining a function with C# or VB.NET is simply a matter of writing the function and decorating it with the ExcelFunction attribute. 1 2 3 4 5 6 7 8 public class MyFunctions { [ExcelFunction] public static int Add ( int a , int b ) { return a + b ; } } For a video demonstration click below: Loading the new function Once the project that contains the function is built (compiled), the runtime will automatically load it and make the function available in Excel. Depending on if the function is in a workbook or an extension project, the function will be available in the defining workbook or in all workbooks. ExcelDNA QueryStorm uses the popular ExcelDNA library for registering Excel functions. The functions you define can be simple synchronous functions as shown here, but they can also be asynchronous, accept and return tabular values, cache data internally and do other non-trivial things. More information on these topics, and many more, can be found in the following resources: ExcelDna Google group ExcelDna on StackOverflow ExcelDna wiki on GitHub C# or VB.NET When creating the project, you can choose which language to use: The language setting is stored in the module.config file. 1 \"Language\" : \"CSharp\" ...or... 1 \"Language\" : \"VisualBasic\" The language setting determines the compiler and class templates that the project will use. If you choose VB.NET, the code will be compiled using the VB.NET roslyn compiler, and the scaffolded function files will look something like this: 1 2 3 4 5 6 Public Module MyFunctions1 <ExcelFunction> Public Function Add(val1 As Int32, val2 As Int32) as int32 return val1 + val2 End Function End Module Dependencies Simple functions that do not rely on any shared dependencies can be static and do everything on their own. However, a function might need to get hold of a particular service (e.g. an API object) in order to perform its calculation. That service might be expensive to create, so we would not want to create a new instance each time the function is evaluated. It would be better to have a single instance of the service which would be reused in each function call. If the function relies on such dependencies, it should not be static. The constructor of the class that owns the function is executed only once (just before the first function call), so any expensive dependencies can be created there. However, if multiple functions should share the same dependency, the dependency should be registered centrally, in the IOC container in the App class (inside the App.cs file). The constructor of the function's class can then request the service by simply declaring it as a constructor argument (constructor injection). For example, we can register the service in App.cs: 1 2 3 4 5 6 public App ( IUnityContainer container ) : base ( container ) { // register the service as a singleton container . RegisterType < SomeService >( new ContainerControlledLifetimeManager ()); } We can then use the service in our function: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ExcelFunctions1 { SomeService someService ; // request the service by adding a ctor argument public ExcelFunctions1 ( SomeService someService ) { this . someService = someService ; } [ExcelFunction] public int Add ( int a , int b ) { // use the service to perform the calculation return someService . Add ( a , b ); } } QueryStorm uses the Unity container for dependency injection. Debugging functions QueryStorm does not currently have a built-in debugger, but there are two static methods that help with debugging: Log() and Debug() . The Log() method The simplest way to debug issues is to use the Log(object obj) method to print values to the messages pane. The Log() method is contained in the QueryStorm.Core.DebugHelpers class. All class files that QueryStorm generates have a static using directive for that class, so you can use the Log method anywhere in your code, without qualifying it with the namespace or the class name. It's important to note that QueryStorm has two log viewers. One is part of the IDE, and the other is part of the Runtime (launched separately from the ribbon). The output of the Log() method will be visible in both places, so Runtime users will be able to see these messages. Attaching a debugger The Log() method is useful, but quite often a proper debugger is needed to track down tricky bugs. QueryStorm compiles code in a debugger-friendly way, so it's fairly easy to debug your code with an external debugger. To launch a debugger at a particular location in the source code, use the Debug() method. The Debug() method is also available anywhere in the code without prefixing it with the namespace or the class name, due to the using directive that's part of all code files generated by QueryStorm. If the local machine has Visual Studio installed, the Debug() method will launch Visual Studio, attach it to the process and stop the debugger at the current line. If a debugger is already attached, it will simply stop at the line with the Debug() call. If you do not have Visual Studio installed, you can use the small open source DNSpy debugger, attach it to the Excel process, and use the Debug() method to stop the debugger at the desired line in the code.","title":"Functions via .Net"},{"location":"Functions/Functions_via_DotNet/#defining-functions-with-net","text":"The process of defining a function with C# or VB.NET is simply a matter of writing the function and decorating it with the ExcelFunction attribute. 1 2 3 4 5 6 7 8 public class MyFunctions { [ExcelFunction] public static int Add ( int a , int b ) { return a + b ; } } For a video demonstration click below:","title":"Defining functions with .NET"},{"location":"Functions/Functions_via_DotNet/#loading-the-new-function","text":"Once the project that contains the function is built (compiled), the runtime will automatically load it and make the function available in Excel. Depending on if the function is in a workbook or an extension project, the function will be available in the defining workbook or in all workbooks.","title":"Loading the new function"},{"location":"Functions/Functions_via_DotNet/#exceldna","text":"QueryStorm uses the popular ExcelDNA library for registering Excel functions. The functions you define can be simple synchronous functions as shown here, but they can also be asynchronous, accept and return tabular values, cache data internally and do other non-trivial things. More information on these topics, and many more, can be found in the following resources: ExcelDna Google group ExcelDna on StackOverflow ExcelDna wiki on GitHub","title":"ExcelDNA"},{"location":"Functions/Functions_via_DotNet/#c-or-vbnet","text":"When creating the project, you can choose which language to use: The language setting is stored in the module.config file. 1 \"Language\" : \"CSharp\" ...or... 1 \"Language\" : \"VisualBasic\" The language setting determines the compiler and class templates that the project will use. If you choose VB.NET, the code will be compiled using the VB.NET roslyn compiler, and the scaffolded function files will look something like this: 1 2 3 4 5 6 Public Module MyFunctions1 <ExcelFunction> Public Function Add(val1 As Int32, val2 As Int32) as int32 return val1 + val2 End Function End Module","title":"C# or VB.NET"},{"location":"Functions/Functions_via_DotNet/#dependencies","text":"Simple functions that do not rely on any shared dependencies can be static and do everything on their own. However, a function might need to get hold of a particular service (e.g. an API object) in order to perform its calculation. That service might be expensive to create, so we would not want to create a new instance each time the function is evaluated. It would be better to have a single instance of the service which would be reused in each function call. If the function relies on such dependencies, it should not be static. The constructor of the class that owns the function is executed only once (just before the first function call), so any expensive dependencies can be created there. However, if multiple functions should share the same dependency, the dependency should be registered centrally, in the IOC container in the App class (inside the App.cs file). The constructor of the function's class can then request the service by simply declaring it as a constructor argument (constructor injection). For example, we can register the service in App.cs: 1 2 3 4 5 6 public App ( IUnityContainer container ) : base ( container ) { // register the service as a singleton container . RegisterType < SomeService >( new ContainerControlledLifetimeManager ()); } We can then use the service in our function: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ExcelFunctions1 { SomeService someService ; // request the service by adding a ctor argument public ExcelFunctions1 ( SomeService someService ) { this . someService = someService ; } [ExcelFunction] public int Add ( int a , int b ) { // use the service to perform the calculation return someService . Add ( a , b ); } } QueryStorm uses the Unity container for dependency injection.","title":"Dependencies"},{"location":"Functions/Functions_via_DotNet/#debugging-functions","text":"QueryStorm does not currently have a built-in debugger, but there are two static methods that help with debugging: Log() and Debug() .","title":"Debugging functions"},{"location":"Functions/Functions_via_DotNet/#the-log-method","text":"The simplest way to debug issues is to use the Log(object obj) method to print values to the messages pane. The Log() method is contained in the QueryStorm.Core.DebugHelpers class. All class files that QueryStorm generates have a static using directive for that class, so you can use the Log method anywhere in your code, without qualifying it with the namespace or the class name. It's important to note that QueryStorm has two log viewers. One is part of the IDE, and the other is part of the Runtime (launched separately from the ribbon). The output of the Log() method will be visible in both places, so Runtime users will be able to see these messages.","title":"The Log() method"},{"location":"Functions/Functions_via_DotNet/#attaching-a-debugger","text":"The Log() method is useful, but quite often a proper debugger is needed to track down tricky bugs. QueryStorm compiles code in a debugger-friendly way, so it's fairly easy to debug your code with an external debugger. To launch a debugger at a particular location in the source code, use the Debug() method. The Debug() method is also available anywhere in the code without prefixing it with the namespace or the class name, due to the using directive that's part of all code files generated by QueryStorm. If the local machine has Visual Studio installed, the Debug() method will launch Visual Studio, attach it to the process and stop the debugger at the current line. If a debugger is already attached, it will simply stop at the line with the Debug() call. If you do not have Visual Studio installed, you can use the small open source DNSpy debugger, attach it to the Excel process, and use the Debug() method to stop the debugger at the desired line in the code.","title":"Attaching a debugger"},{"location":"Functions/Functions_via_SQL/","text":"Excel functions via SQL QueryStorm allows creating Excel functions that use SQL to return data from a database. The body of the function is written in SQL, while the declaration of the function uses a preprocessor syntax that's specific to QueryStorm. Suppose we'd like to define a function that returns a list of people from the database whose first name contains a specified search term. To define this function, we need to create a new script and connect to our target database. Once connected, we can use the following code to define and test the function: 1 2 3 4 5 6 7 8 9 10 -- the declaration of the function { function searchPeople ( string searchTerm = \"tim\" ) } -- the body of the function select * from Person . Person p where FirstName like '%' + @ searchTerm + '%' We can run the code to examine if it returns the expected results. When running the query, the @searchTerm parameter's default value will be used. In this example, the query will return all persons whose name contains the string \"tim\" . Running the code simply runs the query, but does not yet register the function with Excel. To register this function with Excel, we must: Save the script Ctrl + S Build the project Ctrl + Shift + B For a video demonstration of the process, click below: Parameters Functions that are declared by the QueryStorm preprocessor can accept parameters. Function parameters have names, types and default values. There are five supported data types for parameters: int , float , datetime , string and bool . The following are examples of valid parameter declarations: int abc = 123 float abc = 12.3 datetime abc = \"2020-08-31\" (ISO 8601 format) string abc = \"some text\" bool abc = true var abc = \"example text\" (auto-detect type) To reference a variable in the body of the SQL query, you can either use preprocessor expressions e.g. {abc} or the standard syntax for parameters, e.g. @abc (for SQL Server). A parameter's default value is only used when the query is directly executed. When the function is called from Excel, the default value of the parameter is ignored. Return values Functions can return a single value or an entire table as their result. If your machine (or the end user's machine) is running one of the newer (Office365) versions of Excel that support dynamic arrays , tabular results will automatically spill. If you are using an older version of Excel, you will need to use Ctrl+Alt+Enter (or {=function()} syntax) to allow the result to return a table of data (however, you'll need to know in advance the size of the output data). Using and sharing functions So once you've built the function, where can you use it? It depends on where you've created it. Functions can be defined inside a particular workbook or as a QueryStorm extension that's available in all workbooks. Workbook functions If the function is stored inside the workbook, anyone who has the workbook (and the QueryStorm runtime) will be able to use it. However, this function will only be usable in the workbook that contains it. If the function should be usable in any Excel file, you should define it in an \"Extension\" package, as described below. Extension functions QueryStorm supports building extension projects which can contain a set of user defined Excel functions that can be packaged together and published to other users. To define the function in a QueryStorm extension rather than in the workbook, create a new project in \"Code explorer\" and then add a new script from the context menu of the new project. For a video demonstration of this process, click below: Publishing functions Functions that are defined in extension projects can be published to other QueryStorm (Runtime) users. For more information on this, click here .","title":"Functions via SQL"},{"location":"Functions/Functions_via_SQL/#excel-functions-via-sql","text":"QueryStorm allows creating Excel functions that use SQL to return data from a database. The body of the function is written in SQL, while the declaration of the function uses a preprocessor syntax that's specific to QueryStorm. Suppose we'd like to define a function that returns a list of people from the database whose first name contains a specified search term. To define this function, we need to create a new script and connect to our target database. Once connected, we can use the following code to define and test the function: 1 2 3 4 5 6 7 8 9 10 -- the declaration of the function { function searchPeople ( string searchTerm = \"tim\" ) } -- the body of the function select * from Person . Person p where FirstName like '%' + @ searchTerm + '%' We can run the code to examine if it returns the expected results. When running the query, the @searchTerm parameter's default value will be used. In this example, the query will return all persons whose name contains the string \"tim\" . Running the code simply runs the query, but does not yet register the function with Excel. To register this function with Excel, we must: Save the script Ctrl + S Build the project Ctrl + Shift + B For a video demonstration of the process, click below:","title":"Excel functions via SQL"},{"location":"Functions/Functions_via_SQL/#parameters","text":"Functions that are declared by the QueryStorm preprocessor can accept parameters. Function parameters have names, types and default values. There are five supported data types for parameters: int , float , datetime , string and bool . The following are examples of valid parameter declarations: int abc = 123 float abc = 12.3 datetime abc = \"2020-08-31\" (ISO 8601 format) string abc = \"some text\" bool abc = true var abc = \"example text\" (auto-detect type) To reference a variable in the body of the SQL query, you can either use preprocessor expressions e.g. {abc} or the standard syntax for parameters, e.g. @abc (for SQL Server). A parameter's default value is only used when the query is directly executed. When the function is called from Excel, the default value of the parameter is ignored.","title":"Parameters"},{"location":"Functions/Functions_via_SQL/#return-values","text":"Functions can return a single value or an entire table as their result. If your machine (or the end user's machine) is running one of the newer (Office365) versions of Excel that support dynamic arrays , tabular results will automatically spill. If you are using an older version of Excel, you will need to use Ctrl+Alt+Enter (or {=function()} syntax) to allow the result to return a table of data (however, you'll need to know in advance the size of the output data).","title":"Return values"},{"location":"Functions/Functions_via_SQL/#using-and-sharing-functions","text":"So once you've built the function, where can you use it? It depends on where you've created it. Functions can be defined inside a particular workbook or as a QueryStorm extension that's available in all workbooks.","title":"Using and sharing functions"},{"location":"Functions/Functions_via_SQL/#workbook-functions","text":"If the function is stored inside the workbook, anyone who has the workbook (and the QueryStorm runtime) will be able to use it. However, this function will only be usable in the workbook that contains it. If the function should be usable in any Excel file, you should define it in an \"Extension\" package, as described below.","title":"Workbook functions"},{"location":"Functions/Functions_via_SQL/#extension-functions","text":"QueryStorm supports building extension projects which can contain a set of user defined Excel functions that can be packaged together and published to other users. To define the function in a QueryStorm extension rather than in the workbook, create a new project in \"Code explorer\" and then add a new script from the context menu of the new project. For a video demonstration of this process, click below:","title":"Extension functions"},{"location":"Functions/Functions_via_SQL/#publishing-functions","text":"Functions that are defined in extension projects can be published to other QueryStorm (Runtime) users. For more information on this, click here .","title":"Publishing functions"},{"location":"Functions/Installing_packages/","text":"Installing packages Extension packages are created and published from the QueryStorm IDE by package creators, and are installed and used from the QueryStorm Runtime by end users. An extension package contains one or more custom Excel functions. A typical scenario for QueryStorm extensions is as follows: A developer uses the QueryStorm IDE to write a set of Excel functions (in C#, VB.NET or SQL) for a particular purpose Once they've prepared the functions, they publish the package that contains them to a feed End users install the package using the Extensions manager in the QueryStorm Runtime The end users use the new functions in their Excel workbooks Managing NuGet sources Package creators publish packages to a feed. This is typically a feed that's owned by the package creator. In order to be able to browse packages that a creator has prepared, you must add their feed into your list of feeds. The creator is responsible for providing you the with the URL to their feed. Once you have the URL, you can add it to your list of feeds. The list of feeds is edited in the Extensions Manager dialog as shown below. Area for managing sources (feeds) Button for editing the feed Feed url or path Feed content type (Packages, Extensions or Both) Both creators and consumers use the above dialog to edit their package feeds.","title":"Installing packages"},{"location":"Functions/Installing_packages/#installing-packages","text":"Extension packages are created and published from the QueryStorm IDE by package creators, and are installed and used from the QueryStorm Runtime by end users. An extension package contains one or more custom Excel functions. A typical scenario for QueryStorm extensions is as follows: A developer uses the QueryStorm IDE to write a set of Excel functions (in C#, VB.NET or SQL) for a particular purpose Once they've prepared the functions, they publish the package that contains them to a feed End users install the package using the Extensions manager in the QueryStorm Runtime The end users use the new functions in their Excel workbooks","title":"Installing packages"},{"location":"Functions/Installing_packages/#managing-nuget-sources","text":"Package creators publish packages to a feed. This is typically a feed that's owned by the package creator. In order to be able to browse packages that a creator has prepared, you must add their feed into your list of feeds. The creator is responsible for providing you the with the URL to their feed. Once you have the URL, you can add it to your list of feeds. The list of feeds is edited in the Extensions Manager dialog as shown below. Area for managing sources (feeds) Button for editing the feed Feed url or path Feed content type (Packages, Extensions or Both) Both creators and consumers use the above dialog to edit their package feeds.","title":"Managing NuGet sources"},{"location":"Functions/Overview/","text":"Custom Excel functions QueryStorm enables user to add new functions to Excel. Users who use the full version of QueryStorm can build their own custom functions as well as publish them to other users. Users who use the Runtime version of QueryStorm can install packages published by creators, but cannot create their own functions. Supported languages QueryStorm lets you define new Excel functions using SQL , C# and VB.NET . Creating functions via SQL Defining functions in SQL is useful for returning data from databases. The function body is written in SQL, while the function declaration uses a simple preprocessor syntax that's available in all SQL scripts in QueryStorm. For example: 1 2 3 4 5 6 7 8 9 10 -- the declaration of the function { function searchPeople ( string searchTerm = \"tim\" ) } -- the body of the function select * from Person . Person p where p . FirstName like '%' + @ searchTerm + '%' To read more about creating functions with SQL, click here . Creating functions via C# and VB.NET Building functions in C# and VB.NET is a matter of writing the code of the function and decorating it with the ExcelFunction attribute. The function might perform a calculation on its own, or it might call into some third party library or a REST service. For example: 1 2 3 4 5 6 7 8 public class MyFunctions { [ExcelFunction] public static int Add ( int a , int b ) { return a + b ; } } The user can choose the language (C# or VB.NET) they wish to use in the module.config file. To read more about creating functions with C# and VB.NET, click here . Where functions are stored Functions can be defined inside a particular workbook or in an extension package . Functions in the workbook Functions that are defined inside a workbook are only available to that workbook. The advantage to this is that they will be immediately available to others when they open a copy of your workbook (provided they have the QueryStorm runtime), so you don't need to distribute them separately. Functions in an extension package Functions can also be defined in extension packages . Functions contained in an extension package are usable in any workbook on the machine. Authors can easily publish their extension packages to make them available to other (QueryStorm Runtime) users. Click here for more information about publishing extension packages.","title":"Overview"},{"location":"Functions/Overview/#custom-excel-functions","text":"QueryStorm enables user to add new functions to Excel. Users who use the full version of QueryStorm can build their own custom functions as well as publish them to other users. Users who use the Runtime version of QueryStorm can install packages published by creators, but cannot create their own functions.","title":"Custom Excel functions"},{"location":"Functions/Overview/#supported-languages","text":"QueryStorm lets you define new Excel functions using SQL , C# and VB.NET .","title":"Supported languages"},{"location":"Functions/Overview/#creating-functions-via-sql","text":"Defining functions in SQL is useful for returning data from databases. The function body is written in SQL, while the function declaration uses a simple preprocessor syntax that's available in all SQL scripts in QueryStorm. For example: 1 2 3 4 5 6 7 8 9 10 -- the declaration of the function { function searchPeople ( string searchTerm = \"tim\" ) } -- the body of the function select * from Person . Person p where p . FirstName like '%' + @ searchTerm + '%' To read more about creating functions with SQL, click here .","title":"Creating functions via SQL"},{"location":"Functions/Overview/#creating-functions-via-c-and-vbnet","text":"Building functions in C# and VB.NET is a matter of writing the code of the function and decorating it with the ExcelFunction attribute. The function might perform a calculation on its own, or it might call into some third party library or a REST service. For example: 1 2 3 4 5 6 7 8 public class MyFunctions { [ExcelFunction] public static int Add ( int a , int b ) { return a + b ; } } The user can choose the language (C# or VB.NET) they wish to use in the module.config file. To read more about creating functions with C# and VB.NET, click here .","title":"Creating functions via C# and VB.NET"},{"location":"Functions/Overview/#where-functions-are-stored","text":"Functions can be defined inside a particular workbook or in an extension package .","title":"Where functions are stored"},{"location":"Functions/Overview/#functions-in-the-workbook","text":"Functions that are defined inside a workbook are only available to that workbook. The advantage to this is that they will be immediately available to others when they open a copy of your workbook (provided they have the QueryStorm runtime), so you don't need to distribute them separately.","title":"Functions in the workbook"},{"location":"Functions/Overview/#functions-in-an-extension-package","text":"Functions can also be defined in extension packages . Functions contained in an extension package are usable in any workbook on the machine. Authors can easily publish their extension packages to make them available to other (QueryStorm Runtime) users. Click here for more information about publishing extension packages.","title":"Functions in an extension package"},{"location":"Functions/Publishing_functions/","text":"Publishing packages When an extension package is built (compiled), the functions it contains are immediately registered and available on the local machine. To make them available to other users, however, you need to publish the package. To publish an extensions package, follow these steps: Build the project Right-click on the project and select \"Publish\" Choose the feed to publish to Enter information about the package Managing feeds (sources) Before you can publish packages, though, you will likely need to set up a feed that you can publish to. QueryStorm supports publishing to a network share or to an online server. If you are distributing packages inside your network, a shared network folder would be a good place to store them. If you want to distribute packages to users outside of your local network (e.g. to your clients), you can publish the package to an online NuGet server, like Azure Artifacts ( instructions below ). In both cases, the feed needs to be added to your list of feeds before you can publish to it. The list of feeds is edited in the Package Manager or in the Extensions manager dialog as shown below. The dialog can be opened via the Extensions button in the QueryStorm ribbon, or via the Manage packages context menu for projects. Tab for managing sources (feeds) Button for editing the feed Feed url or path Feed content type (Packages, Extensions or Both) Both creators and consumers use the above dialog to edit their package feeds. Publishing to a network share Adding a network share as a source is fairly straightforward: Click the \"Add source\" button to add a new source Give the new source an arbitrary name Enter the path to the network share in the \"URL\" field Select \"QueryStorm Extensions\" in the \"Feed type\" field Once that's done, you can publish your packages to this source. No credentials are required for publishing to a network share. Publishing to Azure artifacts Azure Artifacts is a cloud-based package management solution that allows you to create and share NuGet packages via feeds that can be public or private. Setting up a feed takes just a few minutes and is free of charge. Currently, the free plan allows for up to 2GB of storage, which is enough for thousands of packages and should be more than enough for most organizations. Should you need more space, scaling is quite easy and fairly affordable as well. For a video of the process of setting up an Azure Artifacts feed, please click below: Creating the feed To create an Azure artifacts feed, follow the steps below: Go to http://dev.azure.com/ and create an account After signing in, create a new project ( public ) Select the Artifacts tab Click \"Create Feed\" and give the feed a name Click \"Connect to Feed\" Click \"Visual Studio\" and copy the source link Go to QueryStorm in Excel and add a new package source with the url from the previous step Creating credentials In order to be able to publish to this feed, you'll also need to set up a personal access token, which you can use as the password. To do so, follow these steps: Click on the user settings in the top right corner of the page (in the azure webpage) Select \"Personal Access Token\" Set token expiration date Grant the token full access Copy the generated token In QueryStorm, enter the token as the password of the new feed and your email address (that's associated with your Azure account) as the username That's it. You can now publish to your new feed! The only thing left to do is to share the feed URL with your users so they can add it to their list of sources. Updating packages When publishing a new version of an existing package, make sure to increment the version number , otherwise the server will report a collision with the version that is already on the server. If the repository is a network share, though, there will be no version checks.","title":"Publishing functions"},{"location":"Functions/Publishing_functions/#publishing-packages","text":"When an extension package is built (compiled), the functions it contains are immediately registered and available on the local machine. To make them available to other users, however, you need to publish the package. To publish an extensions package, follow these steps: Build the project Right-click on the project and select \"Publish\" Choose the feed to publish to Enter information about the package","title":"Publishing packages"},{"location":"Functions/Publishing_functions/#managing-feeds-sources","text":"Before you can publish packages, though, you will likely need to set up a feed that you can publish to. QueryStorm supports publishing to a network share or to an online server. If you are distributing packages inside your network, a shared network folder would be a good place to store them. If you want to distribute packages to users outside of your local network (e.g. to your clients), you can publish the package to an online NuGet server, like Azure Artifacts ( instructions below ). In both cases, the feed needs to be added to your list of feeds before you can publish to it. The list of feeds is edited in the Package Manager or in the Extensions manager dialog as shown below. The dialog can be opened via the Extensions button in the QueryStorm ribbon, or via the Manage packages context menu for projects. Tab for managing sources (feeds) Button for editing the feed Feed url or path Feed content type (Packages, Extensions or Both) Both creators and consumers use the above dialog to edit their package feeds.","title":"Managing feeds (sources)"},{"location":"Functions/Publishing_functions/#publishing-to-a-network-share","text":"Adding a network share as a source is fairly straightforward: Click the \"Add source\" button to add a new source Give the new source an arbitrary name Enter the path to the network share in the \"URL\" field Select \"QueryStorm Extensions\" in the \"Feed type\" field Once that's done, you can publish your packages to this source. No credentials are required for publishing to a network share.","title":"Publishing to a network share"},{"location":"Functions/Publishing_functions/#publishing-to-azure-artifacts","text":"Azure Artifacts is a cloud-based package management solution that allows you to create and share NuGet packages via feeds that can be public or private. Setting up a feed takes just a few minutes and is free of charge. Currently, the free plan allows for up to 2GB of storage, which is enough for thousands of packages and should be more than enough for most organizations. Should you need more space, scaling is quite easy and fairly affordable as well. For a video of the process of setting up an Azure Artifacts feed, please click below:","title":"Publishing to Azure artifacts"},{"location":"Functions/Publishing_functions/#creating-the-feed","text":"To create an Azure artifacts feed, follow the steps below: Go to http://dev.azure.com/ and create an account After signing in, create a new project ( public ) Select the Artifacts tab Click \"Create Feed\" and give the feed a name Click \"Connect to Feed\" Click \"Visual Studio\" and copy the source link Go to QueryStorm in Excel and add a new package source with the url from the previous step","title":"Creating the feed"},{"location":"Functions/Publishing_functions/#creating-credentials","text":"In order to be able to publish to this feed, you'll also need to set up a personal access token, which you can use as the password. To do so, follow these steps: Click on the user settings in the top right corner of the page (in the azure webpage) Select \"Personal Access Token\" Set token expiration date Grant the token full access Copy the generated token In QueryStorm, enter the token as the password of the new feed and your email address (that's associated with your Azure account) as the username That's it. You can now publish to your new feed! The only thing left to do is to share the feed URL with your users so they can add it to their list of sources.","title":"Creating credentials"},{"location":"Functions/Publishing_functions/#updating-packages","text":"When publishing a new version of an existing package, make sure to increment the version number , otherwise the server will report a collision with the version that is already on the server. If the repository is a network share, though, there will be no version checks.","title":"Updating packages"},{"location":"General/Data_context/","text":"The data context The data context represents the outside world that scripts and components see. It exposes tables, variables and events. When you create a script, a data context instance is automatically passed to the script, making its data available to the script. Components can access the data inside the context via property bindings, and component methods can handle events coming from the data context. Each project can have no more than one data context file. You can define your own data context class to customize the data that will be available to your scripts and components, but if not, a default data context will be used. Defining a data context context file The data context file can be added from the project's context menu. This generates a data context file. You can use this file to add additional tables to your data context: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 using System ; using System.Collections.Generic ; using System.Linq ; using System.Text ; using QueryStorm.Core ; using static QueryStorm . Core . DebugHelpers ; namespace aa { public partial class AppDataContext : DataContext { public AppDataContext () { } public override void Initialize () { // create a sample table var folder = Environment . GetFolderPath ( Environment . SpecialFolder . MyDocuments ); var listOfFiles = System . IO . Directory . GetFiles ( folder ); var myFilesTbl = new TabularValue ( listOfFiles , \"myFiles\" ); // add it to the context Tables . Add ( myFilesTbl ); } } } Adding the table to the Tables collection will make it available to your scripts and components. To use the new table in scripts, be sure to compile the project first (before starting the script). Generating table accessor types Data contexts define tables as implementations of the abstract class Tabular , which provides read and write access to tabular data. This data can represent a workbook table, a CSV file, a Google sheets table, data from some API, or any other data that can be represented as a table. Components can bind directly to Tabular instances that the data context exposes: 1 2 [BindTable] public Tabular Departments { get ; set ; } However, a Tabular instance does not offer strongly typed access to the data it contains. To allow strongly typed access to all tables inside the context, QueryStorm dynamically generates a dll file which contains types that correspond to tables in the data context. This dll is recreated each time the data context changes (e.g. an Excel table is changed) and is stored in the lib folder. Components can then bind to these strongly typed table wrappers: 1 2 [BindTable] public DepartmentsTable Departments { get ; set ; } C# scripts can also easily use them as well: 1 Departments . Where ( d => d . Name . StartsWith ( \"Sa\" )) The WorkbookDataContext For workbook projects, a WorkbookDataContext is used to provide access to the workbook data: Excel tables are exposed as tables Single-cell named ranges are exposed as variables Workbook events (e.g. button click) are exposed as events If you do not add a data context file to your project explicitly, an instance of WorkbookDataContext will be used implicitly to provide scripts and components access to workbook data. However, adding a data context file to your project, allows you to: Customize column data types Add relationships between tables Register additional external tables The schema file Excel does not provide a way to define column types for workbook tables, so the WorkbookDataContext has to guess at their types. It takes a fairly conservative guess but it might not guess the type you want. Furthermore, setting up table relationships also isn't natively supported in Excel. Specifying column types and table relations explicitly allows you to influence the generated classes that offer strongly typed access to tables. To enable the user to configure column types and table relations, an additional schema definition file is generated when adding a data context file for a workbook project: This file contains a single method whose job it is to specify column types and table relationships. For example: 1 2 3 4 5 6 7 8 9 protected override void Initialize ( ContextSchema schema ) { schema . ConfigureTable ( \"Employees\" ) // set column types . ConfigureColumn < System . Int32 >( \"Id\" ) . ConfigureColumn < System . String >( \"Name\" ) // add table relation . AddRelation ( \"DptId\" , To . One , \"Departments\" , \"Id\" , \"MyDepartment\" ); } Once the project is compiled, components and C# scripts will be able to see the changes in column types and use the new relation navigation properties. In the example code above, a relation property called MyDepartment was added to the Employee table. After building the project, it can be used in C# scripts like so: The schema file can be edited by hand, as well as updated automatically when tables are changed in Excel. When you add or remove workbook tables (or columns) in Excel, you can run the \"Update schema file\" command on the data context to update the schema file. Configuration code for tables and columns will be added/removed, but settings for existing tables and columns will remain intact. Previous settings are loaded from the output dll, so if you've made manual changes, make sure to build the project before updating the schema file, otherwise those manual changes will be lost. Tip: for performance reasons (to avoid type conversions), it's slightly better to leave Id columns as double instead of int . This is because Excel does not have an int type; all numbers in Excel are double .","title":"Data context"},{"location":"General/Data_context/#the-data-context","text":"The data context represents the outside world that scripts and components see. It exposes tables, variables and events. When you create a script, a data context instance is automatically passed to the script, making its data available to the script. Components can access the data inside the context via property bindings, and component methods can handle events coming from the data context. Each project can have no more than one data context file. You can define your own data context class to customize the data that will be available to your scripts and components, but if not, a default data context will be used.","title":"The data context"},{"location":"General/Data_context/#defining-a-data-context-context-file","text":"The data context file can be added from the project's context menu. This generates a data context file. You can use this file to add additional tables to your data context: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 using System ; using System.Collections.Generic ; using System.Linq ; using System.Text ; using QueryStorm.Core ; using static QueryStorm . Core . DebugHelpers ; namespace aa { public partial class AppDataContext : DataContext { public AppDataContext () { } public override void Initialize () { // create a sample table var folder = Environment . GetFolderPath ( Environment . SpecialFolder . MyDocuments ); var listOfFiles = System . IO . Directory . GetFiles ( folder ); var myFilesTbl = new TabularValue ( listOfFiles , \"myFiles\" ); // add it to the context Tables . Add ( myFilesTbl ); } } } Adding the table to the Tables collection will make it available to your scripts and components. To use the new table in scripts, be sure to compile the project first (before starting the script).","title":"Defining a data context context file"},{"location":"General/Data_context/#generating-table-accessor-types","text":"Data contexts define tables as implementations of the abstract class Tabular , which provides read and write access to tabular data. This data can represent a workbook table, a CSV file, a Google sheets table, data from some API, or any other data that can be represented as a table. Components can bind directly to Tabular instances that the data context exposes: 1 2 [BindTable] public Tabular Departments { get ; set ; } However, a Tabular instance does not offer strongly typed access to the data it contains. To allow strongly typed access to all tables inside the context, QueryStorm dynamically generates a dll file which contains types that correspond to tables in the data context. This dll is recreated each time the data context changes (e.g. an Excel table is changed) and is stored in the lib folder. Components can then bind to these strongly typed table wrappers: 1 2 [BindTable] public DepartmentsTable Departments { get ; set ; } C# scripts can also easily use them as well: 1 Departments . Where ( d => d . Name . StartsWith ( \"Sa\" ))","title":"Generating table accessor types"},{"location":"General/Data_context/#the-workbookdatacontext","text":"For workbook projects, a WorkbookDataContext is used to provide access to the workbook data: Excel tables are exposed as tables Single-cell named ranges are exposed as variables Workbook events (e.g. button click) are exposed as events If you do not add a data context file to your project explicitly, an instance of WorkbookDataContext will be used implicitly to provide scripts and components access to workbook data. However, adding a data context file to your project, allows you to: Customize column data types Add relationships between tables Register additional external tables","title":"The WorkbookDataContext"},{"location":"General/Data_context/#the-schema-file","text":"Excel does not provide a way to define column types for workbook tables, so the WorkbookDataContext has to guess at their types. It takes a fairly conservative guess but it might not guess the type you want. Furthermore, setting up table relationships also isn't natively supported in Excel. Specifying column types and table relations explicitly allows you to influence the generated classes that offer strongly typed access to tables. To enable the user to configure column types and table relations, an additional schema definition file is generated when adding a data context file for a workbook project: This file contains a single method whose job it is to specify column types and table relationships. For example: 1 2 3 4 5 6 7 8 9 protected override void Initialize ( ContextSchema schema ) { schema . ConfigureTable ( \"Employees\" ) // set column types . ConfigureColumn < System . Int32 >( \"Id\" ) . ConfigureColumn < System . String >( \"Name\" ) // add table relation . AddRelation ( \"DptId\" , To . One , \"Departments\" , \"Id\" , \"MyDepartment\" ); } Once the project is compiled, components and C# scripts will be able to see the changes in column types and use the new relation navigation properties. In the example code above, a relation property called MyDepartment was added to the Employee table. After building the project, it can be used in C# scripts like so: The schema file can be edited by hand, as well as updated automatically when tables are changed in Excel. When you add or remove workbook tables (or columns) in Excel, you can run the \"Update schema file\" command on the data context to update the schema file. Configuration code for tables and columns will be added/removed, but settings for existing tables and columns will remain intact. Previous settings are loaded from the output dll, so if you've made manual changes, make sure to build the project before updating the schema file, otherwise those manual changes will be lost. Tip: for performance reasons (to avoid type conversions), it's slightly better to leave Id columns as double instead of int . This is because Excel does not have an int type; all numbers in Excel are double .","title":"The schema file"},{"location":"General/Preprocessor/","text":"The SQL Preprocessor QueryStorm introduces a simple preprocessor that's available in all SQL scripts in QueryStorm. The job of the preprocessor is to allow: Using values from workbook cells in SQL code Defining Excel functions Defining Excel commands Inserting values into SQL The preprocessor can be used to insert values from Excel cells into SQL code, for example: 1 select * from people where id = { nameOfCell } The value of the named cell will be inserted instead of the {nameOfCell} placeholder before the query is passed to the SQL engine. This is a purely textual operation. If the inserted value is a string or a date, it is automatically quoted. To prevent quoting, add an exclamation mark before the name of the cell: {!nameOfCell} . This allows inserting raw sql code into the query (sql injection), so caution is advised when doing this. User defined variables Users can also define their own variables in SQL. This is especially useful when working with database engines that do not have their own support for defining variables (e.g. SQLite, Access). A variable can be defined and referenced in the following way: 1 2 3 4 5 6 7 8 9 -- define the variable { var binSize = 20 } SELECT CAST ( totalPay / { binSize } AS int ) * { binSize } AS bin , count ( * ) AS count FROM salaries GROUP BY bin Formatting values before insertion Values can be formatted before inserting into the query. The syntax for formatting is as follows: { variableName | formatSpecifier }. The format specifier is a standard format specifier for the .NET string.Format method. For example: 1 2 3 4 5 6 { datetime myDate = \"2020-10-10\" } SELECT { myDate | \"The date {0:d} is a {0:dddd}\" } -- the output will be: The date 10/10/2020 is a Saturday Preprocessor expressions vs parameters SQL scripts can reference named cells as parameters (if they support named parameters), so inserting values into the query text with the preprocessor usually isn't required. However, there are several reasons why this might be useful: It allows defining and referencing variables with engines that do not natively support user defined variables (e.g. SQLite) It allows formatting values before inserting into SQL code It allows using cell values as parameters when working with databases that do not support named parameters (e.g. ODBC, Access) It allows injecting raw SQL into queries Defining Excel functions The second important task of the preprocessor is declaring functions that can be used from Excel. The body of the function is written in SQL, and the declaration of the function via the preprocessor. For example: 1 2 3 4 5 6 { function myFunction ( int rowsToReturn = 20 ) } select top { rowsToReturn } * from HumanResources . Department d The above query can be used to define an Excel function that accepts a single parameter and returns a table of results. For more information on creating functions with SQL, click here . Defining Excel commands The preprocessor also allows defining commands. SQL code is used for fetching data or modifying data in the database, while the preprocessor syntax is used to declare the command and specify the events that will trigger execution of the command. For example: 1 2 3 { handles Sheet1 ! CommandButton1 } insert into PermanentDbTable from ImportedWorkbookTable If the query returns data from the database (rather than updating the database), the query restults can be written into the workbook by adding an output directive above it, for example: 1 2 3 4 5 6 7 8 9 10 { handles Sheet1 ! CommandButton1 } { @ OverdueBooks } select BookName , PersonName from BookRentals where ReturnDate < date () and Returned = 0 Running this query will immediately update the OverdueBooks table in Excel with the results. For more information on setting up automation with SQL, click here .","title":"SQL Preprocessor"},{"location":"General/Preprocessor/#the-sql-preprocessor","text":"QueryStorm introduces a simple preprocessor that's available in all SQL scripts in QueryStorm. The job of the preprocessor is to allow: Using values from workbook cells in SQL code Defining Excel functions Defining Excel commands","title":"The SQL Preprocessor"},{"location":"General/Preprocessor/#inserting-values-into-sql","text":"The preprocessor can be used to insert values from Excel cells into SQL code, for example: 1 select * from people where id = { nameOfCell } The value of the named cell will be inserted instead of the {nameOfCell} placeholder before the query is passed to the SQL engine. This is a purely textual operation. If the inserted value is a string or a date, it is automatically quoted. To prevent quoting, add an exclamation mark before the name of the cell: {!nameOfCell} . This allows inserting raw sql code into the query (sql injection), so caution is advised when doing this.","title":"Inserting values into SQL"},{"location":"General/Preprocessor/#user-defined-variables","text":"Users can also define their own variables in SQL. This is especially useful when working with database engines that do not have their own support for defining variables (e.g. SQLite, Access). A variable can be defined and referenced in the following way: 1 2 3 4 5 6 7 8 9 -- define the variable { var binSize = 20 } SELECT CAST ( totalPay / { binSize } AS int ) * { binSize } AS bin , count ( * ) AS count FROM salaries GROUP BY bin","title":"User defined variables"},{"location":"General/Preprocessor/#formatting-values-before-insertion","text":"Values can be formatted before inserting into the query. The syntax for formatting is as follows: { variableName | formatSpecifier }. The format specifier is a standard format specifier for the .NET string.Format method. For example: 1 2 3 4 5 6 { datetime myDate = \"2020-10-10\" } SELECT { myDate | \"The date {0:d} is a {0:dddd}\" } -- the output will be: The date 10/10/2020 is a Saturday","title":"Formatting values before insertion"},{"location":"General/Preprocessor/#preprocessor-expressions-vs-parameters","text":"SQL scripts can reference named cells as parameters (if they support named parameters), so inserting values into the query text with the preprocessor usually isn't required. However, there are several reasons why this might be useful: It allows defining and referencing variables with engines that do not natively support user defined variables (e.g. SQLite) It allows formatting values before inserting into SQL code It allows using cell values as parameters when working with databases that do not support named parameters (e.g. ODBC, Access) It allows injecting raw SQL into queries","title":"Preprocessor expressions vs parameters"},{"location":"General/Preprocessor/#defining-excel-functions","text":"The second important task of the preprocessor is declaring functions that can be used from Excel. The body of the function is written in SQL, and the declaration of the function via the preprocessor. For example: 1 2 3 4 5 6 { function myFunction ( int rowsToReturn = 20 ) } select top { rowsToReturn } * from HumanResources . Department d The above query can be used to define an Excel function that accepts a single parameter and returns a table of results. For more information on creating functions with SQL, click here .","title":"Defining Excel functions"},{"location":"General/Preprocessor/#defining-excel-commands","text":"The preprocessor also allows defining commands. SQL code is used for fetching data or modifying data in the database, while the preprocessor syntax is used to declare the command and specify the events that will trigger execution of the command. For example: 1 2 3 { handles Sheet1 ! CommandButton1 } insert into PermanentDbTable from ImportedWorkbookTable If the query returns data from the database (rather than updating the database), the query restults can be written into the workbook by adding an output directive above it, for example: 1 2 3 4 5 6 7 8 9 10 { handles Sheet1 ! CommandButton1 } { @ OverdueBooks } select BookName , PersonName from BookRentals where ReturnDate < date () and Returned = 0 Running this query will immediately update the OverdueBooks table in Excel with the results. For more information on setting up automation with SQL, click here .","title":"Defining Excel commands"},{"location":"General/Project_system/","text":"The QueryStorm project system Code files in QueryStorm are organized into projects. Projects contain user code, scripts and configuration files, and are fairly similar to projects in Visual Studio. In order to run the code inside a project, the project needs to be built (compiled). The outputs of the Build process are stored inside the bin folder of the project. The outputs will usually consist of the project dll, the debug and documentation files (pdb + xml docs) and a manifest file that's used by the QueryStorm Runtime. Two types of projects There are two kinds of projects in QueryStorm: Workbook projects and Extension projects. Workbook projects are defined inside a particular workbook and serve to automate the workbook, and to define functions that are specific to the containing workbook. Both the code and as the output files of a workbook project are stored inside the workbook itself. Extension projects are defined at the machine-level, and serve to define functions that should be available in all workbooks. Building (compiling) an extension project produces an extension package. Extension packages can be shared with other users by publishing them to a network share or to an online server. They can be downloaded by end users via the Extensions Manager that's part of the QueryStorm runtime. Supported programming languages QueryStorm projects support source code written in C# and VB.NET. While C# is more popular with developers, VB.NET is more familiar to people with VBA experience. The two languages have a somewhat different syntax, but are practically identical in capabilities. Source code for both languages is compiled using Microsoft's Roslyn compiler. You can choose the language for your project when you are creating it. This setting is saved in the module.config file and can be changed manually at a later point if needed: 1 \"Language\" : \"CSharp\" The allowed values are \"CSharp\" and \"VisualBasic\". Alternatively, you can use the number 1 (without quotes) for C# and 2 for VB.NET. This setting affects the compilation of the project, as well as the class templates that are used when adding new files to projects. Kinds of files The project system supports the following kinds of files: Class files (.cs or .vb) contain the logic of your application. Depending on the language of the project, they will have a .cs or .vb extension. The Application file ( App.cs/App.vb ) file defines a class that is the entry point of the application and serves to initialize services, the data context and components. There is a maximum of one App file per project. The data context file defines the tables, variables and events that will be visible to scripts and components. There is a maximum of one data context file per project. Component files are ordinary class files that are generated from a template that provides a skeleton component class. Excel function class files are ordinary class files that are generated from a template that provides an example implementation of a custom Excel function. Script files contain SQL and C# scripts (VB.NET is not supported for scripting) that can process Excel data or fetch data from databases or REST services, or simply run arbitrary code. SQL scripts support a preprocessor syntax that allows defining functions and commands via SQL. Saving a SQL script generates supporting classes that define functions and commands and strongly typed classes for results. The module.config file contains the configuration settings for the project, including a list of library and NuGet references, language selection (CSharp/VisualBasic), connection strings and project metadata (name, version, etc...). Project folders Files can be organized into more-or-less arbitrary folders. The exception are the two folders that have a special meaning, specifically: bin and lib . As mentioned earlier, the bin folder contains the build output of the project. Its contents are cleared before each build, so it should not be used to store any user files. The lib folder contains dll files that were added as library references, as well as dll files that have been downloaded as NuGet packages. All dlls inside this folder are automatically referenced and their types can be used in your code. When publishing a package, the package will contain all files from both the bin and lib folders. Referencing dlls and NuGet packages Projects can use existing libraries in two ways: By installing NuGet packages By referencing local dll files In both cases, dll files are added to the lib folder and are immediately referenced by your project. When referencing a local file, an entry is added to the \"References\" section of the module.config file, while NuGet references are added to the \"Dependencies\" section.","title":"Project system"},{"location":"General/Project_system/#the-querystorm-project-system","text":"Code files in QueryStorm are organized into projects. Projects contain user code, scripts and configuration files, and are fairly similar to projects in Visual Studio. In order to run the code inside a project, the project needs to be built (compiled). The outputs of the Build process are stored inside the bin folder of the project. The outputs will usually consist of the project dll, the debug and documentation files (pdb + xml docs) and a manifest file that's used by the QueryStorm Runtime.","title":"The QueryStorm project system"},{"location":"General/Project_system/#two-types-of-projects","text":"There are two kinds of projects in QueryStorm: Workbook projects and Extension projects. Workbook projects are defined inside a particular workbook and serve to automate the workbook, and to define functions that are specific to the containing workbook. Both the code and as the output files of a workbook project are stored inside the workbook itself. Extension projects are defined at the machine-level, and serve to define functions that should be available in all workbooks. Building (compiling) an extension project produces an extension package. Extension packages can be shared with other users by publishing them to a network share or to an online server. They can be downloaded by end users via the Extensions Manager that's part of the QueryStorm runtime.","title":"Two types of projects"},{"location":"General/Project_system/#supported-programming-languages","text":"QueryStorm projects support source code written in C# and VB.NET. While C# is more popular with developers, VB.NET is more familiar to people with VBA experience. The two languages have a somewhat different syntax, but are practically identical in capabilities. Source code for both languages is compiled using Microsoft's Roslyn compiler. You can choose the language for your project when you are creating it. This setting is saved in the module.config file and can be changed manually at a later point if needed: 1 \"Language\" : \"CSharp\" The allowed values are \"CSharp\" and \"VisualBasic\". Alternatively, you can use the number 1 (without quotes) for C# and 2 for VB.NET. This setting affects the compilation of the project, as well as the class templates that are used when adding new files to projects.","title":"Supported programming languages"},{"location":"General/Project_system/#kinds-of-files","text":"The project system supports the following kinds of files: Class files (.cs or .vb) contain the logic of your application. Depending on the language of the project, they will have a .cs or .vb extension. The Application file ( App.cs/App.vb ) file defines a class that is the entry point of the application and serves to initialize services, the data context and components. There is a maximum of one App file per project. The data context file defines the tables, variables and events that will be visible to scripts and components. There is a maximum of one data context file per project. Component files are ordinary class files that are generated from a template that provides a skeleton component class. Excel function class files are ordinary class files that are generated from a template that provides an example implementation of a custom Excel function. Script files contain SQL and C# scripts (VB.NET is not supported for scripting) that can process Excel data or fetch data from databases or REST services, or simply run arbitrary code. SQL scripts support a preprocessor syntax that allows defining functions and commands via SQL. Saving a SQL script generates supporting classes that define functions and commands and strongly typed classes for results. The module.config file contains the configuration settings for the project, including a list of library and NuGet references, language selection (CSharp/VisualBasic), connection strings and project metadata (name, version, etc...).","title":"Kinds of files"},{"location":"General/Project_system/#project-folders","text":"Files can be organized into more-or-less arbitrary folders. The exception are the two folders that have a special meaning, specifically: bin and lib . As mentioned earlier, the bin folder contains the build output of the project. Its contents are cleared before each build, so it should not be used to store any user files. The lib folder contains dll files that were added as library references, as well as dll files that have been downloaded as NuGet packages. All dlls inside this folder are automatically referenced and their types can be used in your code. When publishing a package, the package will contain all files from both the bin and lib folders.","title":"Project folders"},{"location":"General/Project_system/#referencing-dlls-and-nuget-packages","text":"Projects can use existing libraries in two ways: By installing NuGet packages By referencing local dll files In both cases, dll files are added to the lib folder and are immediately referenced by your project. When referencing a local file, an entry is added to the \"References\" section of the module.config file, while NuGet references are added to the \"Dependencies\" section.","title":"Referencing dlls and NuGet packages"},{"location":"Querying/CSharp/","text":"C# scripts In QueryStorm, user can write C# scripts that interact with the workbook and the data inside it. Scripts can query workbook tables using LINQ, interact with the Excel object model or perform other arbitrary tasks. Querying tables One of the main features C# scripts offer is the ability to query tables using LINQ. For each table in the workbook, a variable is provided that gives strongly typed access to the table data. QueryStorm uses the Reflection.Emit API to dynamically generate classes that represent table rows. This is done on-the-fly, so as you modify Excel tables, QueryStorm immediately updates the generated types. For example, suppose you have a workbook table named salaries that contains data about people's salaries. You could search for people whose salary is greater than 100,000 like so: 1 salaries . Where ( s => s . TotalPay >= 100000 ) C# scripts can also update data in tables. To update a particular row, simply assign new values to its properties. A ForEach extension method is also available to make it easy to update rows in bulk: 1 2 3 salaries . Where ( s => s . FirstName == \"Marty\" ) . ForEach ( s => s . TotalPay = s . TotalPay + 2000 ) Rows can also be deleted individually or in bulk: 1 2 3 4 5 // individually (Delete single row) salaries . Single ( s => s . Id == 123 ). Delete () // in bulk (Delete many rows) salaries . Where ( s => s . TotalPay == 0 ). Delete () Finally, we can also add rows using AddRow and InsertRow methods: 1 2 3 var row = salaries . AddRow (); row . Id = 123 ; row . TotalPay = 123456 ; Column names Table columns in Excel can have names that are not legal C# identifiers. When row properties are generated, characters that are not allowed in C# identifiers are replaced with underscores. For example, if the table has a column named Job Title , the corresponding property will be Job_Title : 1 salaries . GroupBy ( s => s . Job_Title ) Rows also have an indexer property, that allows reading and writing property values by name. The indexer uses the original column name: 1 dynamic jobTitle = row [ \"Job Title\" ] // The return type of the indexer is `dynamic`. Locating rows in Excel Aside from properties that correspond to columns, rows have an additional __address property that can be used to locate rows in Excel. It returns the Excel address of the row. Double-clicking the address in the results grid selects the row in Excel. Double-clicking the row header in the results grid will also select the range in Excel, provided the row contains a valid address. Formatting rows Aside from locating rows in Excel, the __address property can also be used for selectively formatting rows: 1 2 3 4 salaries . Where ( s => s . JobTitle . ToLower (). Contains ( \"manager\" )) . Where ( s => s . TotalPay > 50000 ) . Format ( range => range . Interior . Color = 0 x00ffff ) // hex int (B/G/R) C# scripting syntax The scripting flavor of C# is supported by Roslyn (the C# compiler) and is slightly different from regular C#. Most of the standard C# syntax is valid in scripts, but scripts also allow a more relaxed syntax where you can evaluate expressions, without the ceremony of defining types and methods. For example, we can return the current date like so: 1 DateTime . Now // do NOT terminate with ; The script will return the result of the last expression in the code, unless it is terminated with a semicolon . To return a value from a statement that is not the last statement in the script, an explicit return statement is required: 1 2 3 4 5 6 return Add ( 1 , 2 ); public int Add ( int a , int b ) { return a + b ; } Referencing dlls A C# script is hosted inside a project. The project has a module.config file that specifies, among other things, library and NuGet references. To use local dlls or NuGet packages in your C# scripts, simply add them to the host project. Adding NuGet packages (1) and library references (2). After adding the references to the project, the project needs to be built in order for the script to see the changes. Referencing project code Scripts can also see classes that the containing project exposes. This can be very handy for manual testing of your classes. It's important to note, however, that the script code is not compiled along with the project's class files. Rather, the script references the project's output dll , so it only sees public types that the project exposes. Additionally, a using statement (or namespace prefix) must be used to access the types inside the project. Since the script references the project's output dll, the project needs to be built (compiled) before the script can use its types. Interacting with the workbook directly In addition to having properties for tables and variables, scripts also have a property called UnityContainer that lets them access all of the services that QueryStorm exposes to them. One such service, the IWorkbookAccessor service, can be used to gain access to the workbook that contains the C# script, like so: 1 2 3 4 var workbook = UnityContainer . Resolve < IWorkbookAccessor >(). Workbook ; // e.g. return the path of the current workbook workbook . FullName From there, the user can interact with the workbook via Excel's COM API.","title":"C# scripts"},{"location":"Querying/CSharp/#c-scripts","text":"In QueryStorm, user can write C# scripts that interact with the workbook and the data inside it. Scripts can query workbook tables using LINQ, interact with the Excel object model or perform other arbitrary tasks.","title":"C# scripts"},{"location":"Querying/CSharp/#querying-tables","text":"One of the main features C# scripts offer is the ability to query tables using LINQ. For each table in the workbook, a variable is provided that gives strongly typed access to the table data. QueryStorm uses the Reflection.Emit API to dynamically generate classes that represent table rows. This is done on-the-fly, so as you modify Excel tables, QueryStorm immediately updates the generated types. For example, suppose you have a workbook table named salaries that contains data about people's salaries. You could search for people whose salary is greater than 100,000 like so: 1 salaries . Where ( s => s . TotalPay >= 100000 ) C# scripts can also update data in tables. To update a particular row, simply assign new values to its properties. A ForEach extension method is also available to make it easy to update rows in bulk: 1 2 3 salaries . Where ( s => s . FirstName == \"Marty\" ) . ForEach ( s => s . TotalPay = s . TotalPay + 2000 ) Rows can also be deleted individually or in bulk: 1 2 3 4 5 // individually (Delete single row) salaries . Single ( s => s . Id == 123 ). Delete () // in bulk (Delete many rows) salaries . Where ( s => s . TotalPay == 0 ). Delete () Finally, we can also add rows using AddRow and InsertRow methods: 1 2 3 var row = salaries . AddRow (); row . Id = 123 ; row . TotalPay = 123456 ;","title":"Querying tables"},{"location":"Querying/CSharp/#column-names","text":"Table columns in Excel can have names that are not legal C# identifiers. When row properties are generated, characters that are not allowed in C# identifiers are replaced with underscores. For example, if the table has a column named Job Title , the corresponding property will be Job_Title : 1 salaries . GroupBy ( s => s . Job_Title ) Rows also have an indexer property, that allows reading and writing property values by name. The indexer uses the original column name: 1 dynamic jobTitle = row [ \"Job Title\" ] // The return type of the indexer is `dynamic`.","title":"Column names"},{"location":"Querying/CSharp/#locating-rows-in-excel","text":"Aside from properties that correspond to columns, rows have an additional __address property that can be used to locate rows in Excel. It returns the Excel address of the row. Double-clicking the address in the results grid selects the row in Excel. Double-clicking the row header in the results grid will also select the range in Excel, provided the row contains a valid address.","title":"Locating rows in Excel"},{"location":"Querying/CSharp/#formatting-rows","text":"Aside from locating rows in Excel, the __address property can also be used for selectively formatting rows: 1 2 3 4 salaries . Where ( s => s . JobTitle . ToLower (). Contains ( \"manager\" )) . Where ( s => s . TotalPay > 50000 ) . Format ( range => range . Interior . Color = 0 x00ffff ) // hex int (B/G/R)","title":"Formatting rows"},{"location":"Querying/CSharp/#c-scripting-syntax","text":"The scripting flavor of C# is supported by Roslyn (the C# compiler) and is slightly different from regular C#. Most of the standard C# syntax is valid in scripts, but scripts also allow a more relaxed syntax where you can evaluate expressions, without the ceremony of defining types and methods. For example, we can return the current date like so: 1 DateTime . Now // do NOT terminate with ; The script will return the result of the last expression in the code, unless it is terminated with a semicolon . To return a value from a statement that is not the last statement in the script, an explicit return statement is required: 1 2 3 4 5 6 return Add ( 1 , 2 ); public int Add ( int a , int b ) { return a + b ; }","title":"C# scripting syntax"},{"location":"Querying/CSharp/#referencing-dlls","text":"A C# script is hosted inside a project. The project has a module.config file that specifies, among other things, library and NuGet references. To use local dlls or NuGet packages in your C# scripts, simply add them to the host project. Adding NuGet packages (1) and library references (2). After adding the references to the project, the project needs to be built in order for the script to see the changes.","title":"Referencing dlls"},{"location":"Querying/CSharp/#referencing-project-code","text":"Scripts can also see classes that the containing project exposes. This can be very handy for manual testing of your classes. It's important to note, however, that the script code is not compiled along with the project's class files. Rather, the script references the project's output dll , so it only sees public types that the project exposes. Additionally, a using statement (or namespace prefix) must be used to access the types inside the project. Since the script references the project's output dll, the project needs to be built (compiled) before the script can use its types.","title":"Referencing project code"},{"location":"Querying/CSharp/#interacting-with-the-workbook-directly","text":"In addition to having properties for tables and variables, scripts also have a property called UnityContainer that lets them access all of the services that QueryStorm exposes to them. One such service, the IWorkbookAccessor service, can be used to gain access to the workbook that contains the C# script, like so: 1 2 3 4 var workbook = UnityContainer . Resolve < IWorkbookAccessor >(). Workbook ; // e.g. return the path of the current workbook workbook . FullName From there, the user can interact with the workbook via Excel's COM API.","title":"Interacting with the workbook directly"},{"location":"Querying/Databases/","text":"External databases QueryStorm supports connecting to external databases, allowing you to query workbook tables alongside database tables. This makes moving data between Excel and databases (in both directions) easy and convenient. Currently SQL Server, Postgres, MySql, SQLite and Redshift (via Postgres) are supported, while support for other databases may be rolled out in the future depending on user needs and requests. Querying To connect to a database, click the appropriate button from the dropdown menu in the ribbon. QueryStorm will then prompt you to enter the connection details and select the workbook tables you would like to use in your script. When the connection is established, selected workbook tables are automatically copied to the database as temp tables. Once there, they can be queried or imported into permanent tables via SQL. While connected, any changes that you make to Excel tables are immediately synchronized to the temp tables. Aside from workbook tables, scripts can also see the values of named ranges. These can be used as parameters in your scripts: Only named ranges that refer to a single cell are usable as parameters. Getting data into Excel Query results can be written into the workbook as new tables or used to update existing ones. You can write the results of a query into a new or existing table by selecting a cell in Excel and using the Alt + Ins shortcut key for writing results. You can also output the results directly from the script, by using the SQL preprocessor , which is available in all SQL scripts in QueryStorm. For example, here's how to output the results of a query into an Excel table, using the preprocessor: 1 2 { @ dpt } SELECT * FROM HumanResources . Department When this script is executed, the results of the select query will be written into an Excel table with the name dpt . If the table does not yet exist, it will be created starting at the currently selected cell. If a table called dpt does exists in the current workbook, it will be overwritten by the results of the query. However, only table columns that exist both in the workbook table and in the results are updated . If the workbook table has any columns that are not present in the query results (e.g. calculated columns), those columns will be left intact. To update multiple tables from the same script, we can use multiple output directives: 1 2 3 4 5 { @ dpt } SELECT * FROM HumanResources . Department { @ people } SELECT * FROM Person . Person p Managing connection strings When entering connection details, you must give your connection string a name. The script file stores the connection name, while the actual connection string is stored in the module.config file: Referencing the connection string by name (instead of keeping it in the script file) lets scripts share connection strings. This makes it easier to e.g. redirect all scripts from a development database to a production database. Securing credentials Connection strings can contain sensitive data i.e. database credentials. It's usually not a good idea for developers to leave their database credentials inside scripts that are shared with end users. This is an important consideration when sharing the workbook itself or when building and sharing custom Excel SQL Functions . For this reason, connection strings can be templated . Instead of the actual username and password, the developer puts placeholders inside the connection string. Two placeholders are supported: {username: id_of_the_credentials } {password} The placeholder for the username must provide the identifier of the credentials. The identifier is used for storing and retrieving the credentials. The following is an example of a templated connection string: Server=mssql6.mojsite.com,1555; Database=thingieq_AdventureWorks2014; User Id= {username:my_creds_123} ; Password= {password} When a script attempts to connect using the above connection string, it will search for stored credentials with the id my_creds_123 . If it does not find them, the user will be prompted to enter them: The credentials are then inserted into the connection string instead of the placeholders and a connection attempt is made. If the attempt fails, the prompt reappears. If the attempt succeeds, the credentials are encrypted and stored in a local file for future use. Once the credentials are stored, they are used automatically in the future every time a connection is attempted with a connection string that uses the same credentials ID (e.g. my_creds_123 ). If a connection attempt fails in the future, the user will again be prompted for their credentials. Stored credentials are encrypted using the via the Windows Data Protection API and stored in a file in the user's AppData directory. Only the user that created the file can decrypt the data.","title":"Databases"},{"location":"Querying/Databases/#external-databases","text":"QueryStorm supports connecting to external databases, allowing you to query workbook tables alongside database tables. This makes moving data between Excel and databases (in both directions) easy and convenient. Currently SQL Server, Postgres, MySql, SQLite and Redshift (via Postgres) are supported, while support for other databases may be rolled out in the future depending on user needs and requests.","title":"External databases"},{"location":"Querying/Databases/#querying","text":"To connect to a database, click the appropriate button from the dropdown menu in the ribbon. QueryStorm will then prompt you to enter the connection details and select the workbook tables you would like to use in your script. When the connection is established, selected workbook tables are automatically copied to the database as temp tables. Once there, they can be queried or imported into permanent tables via SQL. While connected, any changes that you make to Excel tables are immediately synchronized to the temp tables. Aside from workbook tables, scripts can also see the values of named ranges. These can be used as parameters in your scripts: Only named ranges that refer to a single cell are usable as parameters.","title":"Querying"},{"location":"Querying/Databases/#getting-data-into-excel","text":"Query results can be written into the workbook as new tables or used to update existing ones. You can write the results of a query into a new or existing table by selecting a cell in Excel and using the Alt + Ins shortcut key for writing results. You can also output the results directly from the script, by using the SQL preprocessor , which is available in all SQL scripts in QueryStorm. For example, here's how to output the results of a query into an Excel table, using the preprocessor: 1 2 { @ dpt } SELECT * FROM HumanResources . Department When this script is executed, the results of the select query will be written into an Excel table with the name dpt . If the table does not yet exist, it will be created starting at the currently selected cell. If a table called dpt does exists in the current workbook, it will be overwritten by the results of the query. However, only table columns that exist both in the workbook table and in the results are updated . If the workbook table has any columns that are not present in the query results (e.g. calculated columns), those columns will be left intact. To update multiple tables from the same script, we can use multiple output directives: 1 2 3 4 5 { @ dpt } SELECT * FROM HumanResources . Department { @ people } SELECT * FROM Person . Person p","title":"Getting data into Excel"},{"location":"Querying/Databases/#managing-connection-strings","text":"When entering connection details, you must give your connection string a name. The script file stores the connection name, while the actual connection string is stored in the module.config file: Referencing the connection string by name (instead of keeping it in the script file) lets scripts share connection strings. This makes it easier to e.g. redirect all scripts from a development database to a production database.","title":"Managing connection strings"},{"location":"Querying/Databases/#securing-credentials","text":"Connection strings can contain sensitive data i.e. database credentials. It's usually not a good idea for developers to leave their database credentials inside scripts that are shared with end users. This is an important consideration when sharing the workbook itself or when building and sharing custom Excel SQL Functions . For this reason, connection strings can be templated . Instead of the actual username and password, the developer puts placeholders inside the connection string. Two placeholders are supported: {username: id_of_the_credentials } {password} The placeholder for the username must provide the identifier of the credentials. The identifier is used for storing and retrieving the credentials. The following is an example of a templated connection string: Server=mssql6.mojsite.com,1555; Database=thingieq_AdventureWorks2014; User Id= {username:my_creds_123} ; Password= {password} When a script attempts to connect using the above connection string, it will search for stored credentials with the id my_creds_123 . If it does not find them, the user will be prompted to enter them: The credentials are then inserted into the connection string instead of the placeholders and a connection attempt is made. If the attempt fails, the prompt reappears. If the attempt succeeds, the credentials are encrypted and stored in a local file for future use. Once the credentials are stored, they are used automatically in the future every time a connection is attempted with a connection string that uses the same credentials ID (e.g. my_creds_123 ). If a connection attempt fails in the future, the user will again be prompted for their credentials. Stored credentials are encrypted using the via the Windows Data Protection API and stored in a file in the user's AppData directory. Only the user that created the file can decrypt the data.","title":"Securing credentials"},{"location":"Querying/Overview/","text":"Querying QueryStorm supports writing SQL and C# scripts that can see Excel tables, and work with data as if it was in a database or in a .NET collection. Tables, not sheets It's important to note that QueryStorm scripts work with Excel tables , and not with ranges or sheets. Press Ctr+T on a cell or a block of cells to convert it to a table. SQL querying QueryStorm comes with a built-in SQLite engine that can work with workbook tables as if they were regular database tables. You can run any valid SQLite query on your data, including UPDATE , INSERT and DELETE statements. Visit the SQLite section for more information. External databases Aside from the built-in SQLite engine, you can also connect to external databases. As you connect, you can choose which tables will be imported into the database as temp tables and thus made available to your scripts. This makes it very easy to move data between Excel and databases. To connect to an external database, choose the appropriate script type in the ribbon. A dialog will appear allowing you to configure the connection and select the tables that should be included in the session as temp tables. Read more about working with external databases here . Querying with C# QueryStorm also allows querying data via C#. Tables are represented as collections of strongly typed objects that you can query and modify. Types that represent table rows are dynamically generated, allowing for strongly typed access to the data. Any changes you make to your workbook tables (e.g. adding a new column or a new table) are immediately reflected in your C# scripts. Read more about QueryStorm's C# scripting support here .","title":"Overview"},{"location":"Querying/Overview/#querying","text":"QueryStorm supports writing SQL and C# scripts that can see Excel tables, and work with data as if it was in a database or in a .NET collection.","title":"Querying"},{"location":"Querying/Overview/#tables-not-sheets","text":"It's important to note that QueryStorm scripts work with Excel tables , and not with ranges or sheets. Press Ctr+T on a cell or a block of cells to convert it to a table.","title":"Tables, not sheets"},{"location":"Querying/Overview/#sql-querying","text":"QueryStorm comes with a built-in SQLite engine that can work with workbook tables as if they were regular database tables. You can run any valid SQLite query on your data, including UPDATE , INSERT and DELETE statements. Visit the SQLite section for more information.","title":"SQL querying"},{"location":"Querying/Overview/#external-databases","text":"Aside from the built-in SQLite engine, you can also connect to external databases. As you connect, you can choose which tables will be imported into the database as temp tables and thus made available to your scripts. This makes it very easy to move data between Excel and databases. To connect to an external database, choose the appropriate script type in the ribbon. A dialog will appear allowing you to configure the connection and select the tables that should be included in the session as temp tables. Read more about working with external databases here .","title":"External databases"},{"location":"Querying/Overview/#querying-with-c","text":"QueryStorm also allows querying data via C#. Tables are represented as collections of strongly typed objects that you can query and modify. Types that represent table rows are dynamically generated, allowing for strongly typed access to the data. Any changes you make to your workbook tables (e.g. adding a new column or a new table) are immediately reflected in your C# scripts. Read more about QueryStorm's C# scripting support here .","title":"Querying with C#"},{"location":"Querying/SQLite/","text":"SQLite QueryStorm comes equipped with a SQLite engine that can work with Excel tables as if they were database tables. Connecting Clicking the SQL button in the ribbon pops up the QueryStorm IDE and creates a new SQLite script that you can use to run queries against the tables in the current workbook. Querying Once connected, we can start querying. It's important to note that the SQLite engine will only see data inside Excel tables . Data that isn't marked as a table will not be visible. To turn a range into a table, select it and press Ctrl+T You can use SQL to query and modify data inside tables. All four SQL data operations are supported: select , insert , update and delete . Any changes that your commands make to the data inside workbook tables will be immediately visible in Excel. The __address column When using the SQLite engine, all workbook tables get an additional column named __address . This column contains the original address of the row in Excel. The __address column is hidden , meaning it is not included in the results if you only specify * in the select list; you must include it in the select list explicitly if you need it (e.g. select *, __address from... ). This column is serves two purposes: Double-clicking the address in the results grid will scroll to the range in Excel and select it The address information can be used for formatting ranges from SQL (described below) Querying cells While the SQLite engine primarily works with Excel tables, it can also work with cells via the xlcells() table-valued function. This is primarily useful when working with unstructured data. The following query returns a list of cells in the current selection: 1 select * from xlcells () We can also return a list of cells in a specified range, like so: 1 select * from xlcells ( 'Sheet1!B5:D9' ) Here's what the returned data looks like: For each cell in the selection, one row is returned in the results. Each cell is described with the following attributes: address , row , column , column letter , value , type , formula . We can use this information to search for cells that satisfy a particular criteria. Aside from reading, the xlcells function can also be used for updating cell values. In that case, xlcells is used as a table in the update query, and its parameter is specified in the where clause. For example, the following query will add 100 to all cells in a range that have a numeric value: 1 2 3 4 5 6 7 update xlcells -- referenced like a table set value = value + 100 where targetRangeAddress = 'H6:I8' -- the function's parameter is here (it's visible in autocomplete) and Type = 'Double' Under the hood, table-valued-functions in SQLite are implemented as virtual tables. Virtual tables can be referenced using the table syntax or the function syntax. When using the table syntax (as shown above), the function's parameters are specified in the WHERE clause. Formatting rows and cells Since the SQLite engine is running in-process with Excel, it can interact with Excel objects. A typical use case for this is modifying formatting. Two functions are provided for this purpose: SetBackgroundColor and ClearBackgroundColor . Here's an example: 1 2 3 4 5 6 7 8 9 10 --first clear any previous formatting from the 'movies' table (the table name is used as the address) select ClearBackgroundColor ( 'movies' ); --apply new formatting to target rows select * , SetBackgroundColor ( __address , 'Orange' ) from movies where gross > 400000000 And the resulting formatting look like this: We can use the same approach to set the background color of individual cells: 1 2 3 4 5 6 7 8 select ClearBackgroundColor ( 'a1:d10' ); select * , SetBackgroundColor ( Address , 'Orange' ) from xlcells ( 'a1:d10' ) x where x . Type = 'Double' Having the formatting functions in the select list might look peculiar. Formatting functions don't return any interesting results, but having them in the select list ensures that they have access to rows that satisfy the where clause. SQL was not designed for imperative code, so unfortunately, there isn't a more appropriate syntax for this. Bulk formatting Formatting row-by-row or cell-by-cell can be quite slow (~1s for 1k rows). When formatting tens of thousands of rows, it's faster to group them together and apply formatting in bulk. For that purpose, you can use the group_address function. This is an aggregate function that converts a group of addresses into a single address with a special syntax. Formatting functions understand this syntax and and can use it to minimize the number of calls to Excel that are needed to preform the formatting. The only change that's needed in the query is to wrap the __address column with the group_address function: 1 2 3 4 5 6 select * , SetBackgroundColor ( group_address ( __address ), 'Orange' ) from movies where gross > 400000000 This small change in the query can make formatting 10k rows take ~200ms instead of ~10s. Indexing columns All columns of Excel tables are automatically indexed by the SQLite engine. This makes joins and searches very fast. However, all of the indexes are single-column indexes and no additional indexes can be defined by the user (for workbook tables). This is because QueryStorm uses SQLite's \"virtual table\" mechanism for representing workbook tables. Virtual tables have the indexing logic baked in and user defined indexes are not supported. If different indexing is needed, you can create a copy of the table and add indexes to the copy, though this is rarely required.","title":"SQLite"},{"location":"Querying/SQLite/#sqlite","text":"QueryStorm comes equipped with a SQLite engine that can work with Excel tables as if they were database tables.","title":"SQLite"},{"location":"Querying/SQLite/#connecting","text":"Clicking the SQL button in the ribbon pops up the QueryStorm IDE and creates a new SQLite script that you can use to run queries against the tables in the current workbook.","title":"Connecting"},{"location":"Querying/SQLite/#querying","text":"Once connected, we can start querying. It's important to note that the SQLite engine will only see data inside Excel tables . Data that isn't marked as a table will not be visible. To turn a range into a table, select it and press Ctrl+T You can use SQL to query and modify data inside tables. All four SQL data operations are supported: select , insert , update and delete . Any changes that your commands make to the data inside workbook tables will be immediately visible in Excel.","title":"Querying"},{"location":"Querying/SQLite/#the-__address-column","text":"When using the SQLite engine, all workbook tables get an additional column named __address . This column contains the original address of the row in Excel. The __address column is hidden , meaning it is not included in the results if you only specify * in the select list; you must include it in the select list explicitly if you need it (e.g. select *, __address from... ). This column is serves two purposes: Double-clicking the address in the results grid will scroll to the range in Excel and select it The address information can be used for formatting ranges from SQL (described below)","title":"The __address column"},{"location":"Querying/SQLite/#querying-cells","text":"While the SQLite engine primarily works with Excel tables, it can also work with cells via the xlcells() table-valued function. This is primarily useful when working with unstructured data. The following query returns a list of cells in the current selection: 1 select * from xlcells () We can also return a list of cells in a specified range, like so: 1 select * from xlcells ( 'Sheet1!B5:D9' ) Here's what the returned data looks like: For each cell in the selection, one row is returned in the results. Each cell is described with the following attributes: address , row , column , column letter , value , type , formula . We can use this information to search for cells that satisfy a particular criteria. Aside from reading, the xlcells function can also be used for updating cell values. In that case, xlcells is used as a table in the update query, and its parameter is specified in the where clause. For example, the following query will add 100 to all cells in a range that have a numeric value: 1 2 3 4 5 6 7 update xlcells -- referenced like a table set value = value + 100 where targetRangeAddress = 'H6:I8' -- the function's parameter is here (it's visible in autocomplete) and Type = 'Double' Under the hood, table-valued-functions in SQLite are implemented as virtual tables. Virtual tables can be referenced using the table syntax or the function syntax. When using the table syntax (as shown above), the function's parameters are specified in the WHERE clause.","title":"Querying cells"},{"location":"Querying/SQLite/#formatting-rows-and-cells","text":"Since the SQLite engine is running in-process with Excel, it can interact with Excel objects. A typical use case for this is modifying formatting. Two functions are provided for this purpose: SetBackgroundColor and ClearBackgroundColor . Here's an example: 1 2 3 4 5 6 7 8 9 10 --first clear any previous formatting from the 'movies' table (the table name is used as the address) select ClearBackgroundColor ( 'movies' ); --apply new formatting to target rows select * , SetBackgroundColor ( __address , 'Orange' ) from movies where gross > 400000000 And the resulting formatting look like this: We can use the same approach to set the background color of individual cells: 1 2 3 4 5 6 7 8 select ClearBackgroundColor ( 'a1:d10' ); select * , SetBackgroundColor ( Address , 'Orange' ) from xlcells ( 'a1:d10' ) x where x . Type = 'Double' Having the formatting functions in the select list might look peculiar. Formatting functions don't return any interesting results, but having them in the select list ensures that they have access to rows that satisfy the where clause. SQL was not designed for imperative code, so unfortunately, there isn't a more appropriate syntax for this.","title":"Formatting rows and cells"},{"location":"Querying/SQLite/#bulk-formatting","text":"Formatting row-by-row or cell-by-cell can be quite slow (~1s for 1k rows). When formatting tens of thousands of rows, it's faster to group them together and apply formatting in bulk. For that purpose, you can use the group_address function. This is an aggregate function that converts a group of addresses into a single address with a special syntax. Formatting functions understand this syntax and and can use it to minimize the number of calls to Excel that are needed to preform the formatting. The only change that's needed in the query is to wrap the __address column with the group_address function: 1 2 3 4 5 6 select * , SetBackgroundColor ( group_address ( __address ), 'Orange' ) from movies where gross > 400000000 This small change in the query can make formatting 10k rows take ~200ms instead of ~10s.","title":"Bulk formatting"},{"location":"Querying/SQLite/#indexing-columns","text":"All columns of Excel tables are automatically indexed by the SQLite engine. This makes joins and searches very fast. However, all of the indexes are single-column indexes and no additional indexes can be defined by the user (for workbook tables). This is because QueryStorm uses SQLite's \"virtual table\" mechanism for representing workbook tables. Virtual tables have the indexing logic baked in and user defined indexes are not supported. If different indexing is needed, you can create a copy of the table and add indexes to the copy, though this is rarely required.","title":"Indexing columns"}]}